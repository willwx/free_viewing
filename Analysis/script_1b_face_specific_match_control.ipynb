{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b3877-02c0-45c5-8e8e-67622c63943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../lib')\n",
    "from storage import get_storage_functions\n",
    "from local_paths import preproc_dir, analysis_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87163e84-7739-45e5-8243-391bb5ddc47c",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c9b1c-bb5c-437a-9e1a-1e0855327000",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# session\n",
    "#============================================================================\n",
    "sess_name = 'sess_name'\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# saccade-matching\n",
    "#============================================================================\n",
    "min_sep = 4  # for non-matched fixation\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# response windows\n",
    "#============================================================================\n",
    "t_pre  = 375\n",
    "t_post = 375\n",
    "t_step =  10\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# statistics\n",
    "#============================================================================\n",
    "match_tests = (\n",
    "    (('Non', 'Face'), 'previous', 'greater'),\n",
    "    (('Face', 'Non'), 'current', 'greater'))\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# paths\n",
    "#============================================================================\n",
    "proc_dir = preproc_dir\n",
    "\n",
    "sdf_dir = preproc_dir\n",
    "sdf_suffix = '-mwa_50'\n",
    "\n",
    "fsn_dir = analysis_dir + 'face_specific'\n",
    "\n",
    "rsc_dir = analysis_dir + 'self_consistency_no_decorr'\n",
    "\n",
    "output_dir = analysis_dir + 'face_specific_match_control'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9522483c-72b1-4b1b-8df1-d4a9b9df57a7",
   "metadata": {},
   "source": [
    "# Check parameters and whether already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16f2001-6f92-47cc-bba0-c03214fb207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_path = Path(proc_dir) / (sess_name + '-proc.h5')\n",
    "print('Loading shared processing from', proc_path)\n",
    "proc_path = proc_path.expanduser()\n",
    "assert proc_path.is_file()\n",
    "\n",
    "sdf_path = Path(sdf_dir) / (sess_name + f'-sdf{sdf_suffix}.h5')\n",
    "print('Loading spike density function from', sdf_path)\n",
    "sdf_path = sdf_path.expanduser()\n",
    "assert sdf_path.is_file()\n",
    "\n",
    "fsn_path = Path(fsn_dir) / (sess_name + '.h5')\n",
    "print('Loading face-specific (per unit) results from', fsn_path)\n",
    "fsn_path = fsn_path.expanduser()\n",
    "assert fsn_path.is_file()\n",
    "\n",
    "rsc_path = Path(rsc_dir) / (sess_name + '.h5')\n",
    "print('Loading return fixation self-consistency results from', rsc_path)\n",
    "rsc_path = rsc_path.expanduser()\n",
    "assert rsc_path.is_file()\n",
    "\n",
    "output_dir = Path(output_dir)\n",
    "assert output_dir.expanduser().is_dir()\n",
    "output_path = output_dir / (sess_name + '.h5')\n",
    "print('Saving results to', output_path)\n",
    "output_path = output_path.expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90613d2f-e9cb-4823-a7a2-5641960dd636",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'face_specific_match_control'\n",
    "\n",
    "if output_path.is_file():\n",
    "    with h5.File(output_path, 'r') as f:\n",
    "        try:\n",
    "            if f[f'progress_report/{analysis_name}/all_done'][()].item():\n",
    "                raise RuntimeError(f'{sess_name} has already been processed')\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb704fe6-058e-43fb-97a4-7a4e711a3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results, add_attr_to_dset, check_equals_saved, link_dsets, copy_group = \\\n",
    "    get_storage_functions(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c26340-c80b-416a-8dcb-4266219379fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = analysis_name + '/config/'\n",
    "save_results(group+'sdf_suffix', sdf_suffix)\n",
    "\n",
    "group = analysis_name + '/config/time_windows/'\n",
    "save_results(group+'t_pre',  t_pre)\n",
    "save_results(group+'t_post',  t_post)\n",
    "save_results(group+'t_step',  t_step)\n",
    "add_attr_to_dset(group, attrs=dict(unit='ms'))\n",
    "\n",
    "group = analysis_name + '/config/statistics/'\n",
    "save_results(group+'tests', str(match_tests))\n",
    "save_results(group+'test_kind', 'mannwhitneyu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc0d61f-94e4-4f73-967d-8baf53195cc4",
   "metadata": {},
   "source": [
    "# Categorize fixations using ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097164d5-6a0c-4956-98ce-b89d9b2e203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_df = pd.read_hdf(proc_path, 'fixation_dataframe', 'r')\n",
    "with h5.File(proc_path, 'r') as f:\n",
    "    random_seed = f['config/default_random_seed'][()]\n",
    "\n",
    "group = 'face_specific/'\n",
    "cat_df = pd.read_hdf(fsn_path, group+'categorization').set_index(['Group', 'Fixation index'])\n",
    "cls_df = pd.read_hdf(fsn_path, group+'cluster_id').set_index(['Group', 'Fixation index'])\n",
    "with h5.File(fsn_path, 'r') as f:\n",
    "    unit_names = f[group+'unit_names'][()].astype(str)\n",
    "    face_cats = list(f[group+'config/face_cats'][()].astype(str))\n",
    "    group_ = f[group+'unit_groups']\n",
    "    unit_groups = [group_[str(i)][()] for i in range(len(group_.keys()))]\n",
    "\n",
    "face_cats_ = list(set(cat_df.columns) & set(face_cats))\n",
    "cat_df['Is non'] = ~cat_df.values.any(1)\n",
    "cat_df['Is face'] = cat_df[face_cats_].values.any(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ecd11-6b78-4fde-a943-b606f55ef2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(analysis_name+'/unit_names', unit_names.astype(bytes))\n",
    "for igroup, usel in enumerate(unit_groups):\n",
    "    save_results(group+f'unit_groups/{igroup}', usel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e931ed5-e32e-4eef-8998-afb16fdeded1",
   "metadata": {},
   "source": [
    "# Find match for saccades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be157168-c7f8-47c7-936c-3a57fb9644cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bycond_return_pairs = {}\n",
    "\n",
    "with h5.File(proc_path, 'r') as f:\n",
    "    sacc_sel = f['saccade_selection/fixation_indices'][()]  # shape (n, 2)\n",
    "    lg_sacc_mask = f['saccade_selection/large/saccade_subset'][()]  # shape (n,) bool mask\n",
    "\n",
    "with h5.File(rsc_path, 'r') as f:\n",
    "    return_thres = f['self_consistency/config/return_criterion/return_thres'][()]\n",
    "    group = f['self_consistency/return_pairs']\n",
    "    for k, v in group.items():\n",
    "        if not k in {v[1] for v in match_tests}: continue\n",
    "        v = v[()]\n",
    "        if not v.size: continue\n",
    "        v = np.sort(v, axis=1)\n",
    "        v = v[np.lexsort(tuple(v.T))]\n",
    "        bycond_return_pairs[k] = v\n",
    "\n",
    "# exclude saccades starting at fix 0 to avoid onset-transient\n",
    "fix_ords = fix_df.index.get_level_values(fix_df.index.names.index('Fixation'))\n",
    "non_zeroth = fix_ords[sacc_sel[0]] != 0\n",
    "non_zeroth = np.nonzero(non_zeroth)[0]\n",
    "for k, v in bycond_return_pairs.items():\n",
    "    m = pd.Series(v[:,0]).isin(non_zeroth).values & pd.Series(v[:,1]).isin(non_zeroth).values\n",
    "    bycond_return_pairs[k] = v = v[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9d6fcb-f06f-421c-ba66-8b4bdd003164",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'face_specific/by_saccade/by_saccade_size/'\n",
    "with h5.File(fsn_path, 'r') as f:\n",
    "    sconds = list(f[group].keys())\n",
    "byscond_sacc_cat_dfs = {\n",
    "    scond: pd.read_hdf(fsn_path, group+scond+'/saccade_categorization').reset_index().drop(columns='index')\n",
    "    for scond in sconds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d9284-d3db-4116-8f5e-7850e643a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "byscond_bytest_match_sacc_df = {}\n",
    "\n",
    "for scond, sacc_cat_df in byscond_sacc_cat_dfs.items():\n",
    "    matched_frac = []\n",
    "    if scond == 'all':\n",
    "        sacc_mask = None\n",
    "    elif scond == 'large':\n",
    "        sacc_mask = lg_sacc_mask\n",
    "    else:\n",
    "        raise ValueError('Unknown saccade condition: '+scond)\n",
    "\n",
    "    byscond_bytest_match_sacc_df[scond] = {}\n",
    "    for test in match_tests:\n",
    "        byscond_bytest_match_sacc_df[scond][test] = {}\n",
    "        match_sacc_df = []\n",
    "\n",
    "        ofix = ['previous', 'current'].index(test[1])\n",
    "        match_cat = test[0][ofix].lower()  # category of matched fixation\n",
    "        match_other_cat = test[0][1-ofix].lower()  # category of the other fixation in sacc\n",
    "        assert f'Is {match_cat}' in cat_df.columns\n",
    "        assert f'Is {match_other_cat}' in cat_df.columns\n",
    "\n",
    "        for igroup, df1 in tqdm(sacc_cat_df.groupby('Group')):\n",
    "            assert not df1.index.has_duplicates\n",
    "\n",
    "            for scat, df2 in df1.groupby(['Fix 1 cat', 'Fix 2 cat']):\n",
    "                # skip saccade categories unrelated to test\n",
    "                if scat != test[0]:\n",
    "                    continue\n",
    "\n",
    "                # ordinal (1st or 2nd) of fixation to be matched\n",
    "                src_ifixs = df2[f'Fix {ofix+1} index'].values\n",
    "                src_other_ifixs = df2[f'Fix {1-ofix+1} index'].values\n",
    "\n",
    "                # matched pairs; contains 2-tuples of indexing into sacc_sel\n",
    "                pairs = bycond_return_pairs[test[1]]\n",
    "\n",
    "                # chose a match for each fixation in a matched src pair\n",
    "                matched = np.zeros(len(src_ifixs), dtype=bool)\n",
    "                match_isaccs = np.empty(len(src_ifixs), dtype=int)  # indexing into sacc_sel\n",
    "\n",
    "                rg = np.random.default_rng(random_seed)\n",
    "                for i, (ifix, other_ifix) in enumerate(zip(src_ifixs, src_other_ifixs)):\n",
    "                    opts = np.nonzero((sacc_sel[ofix,pairs] == ifix).any(1))[0]\n",
    "                    if not opts.size: continue\n",
    "                    src_xy, src_other_xy = fix_df.iloc[[ifix, other_ifix]][['Relative X', 'Relative Y']].values\n",
    "                    src_sacc_size = np.linalg.norm(src_xy - src_other_xy)\n",
    "\n",
    "                    rg.shuffle(opts)\n",
    "                    for opt in opts:\n",
    "                        pair_ifixs = sacc_sel[:,pairs[opt]].T  # (2, 2) rows = sacc1 sacc2, cols = fix1 fix2\n",
    "\n",
    "                        isrc = np.nonzero(pair_ifixs[:,ofix] == ifix)[0].item()  # which of the pair is the source (to-be-paired)\n",
    "\n",
    "                        # require match saccade to be included under sacc_mask (if any)\n",
    "                        if sacc_mask is not None and not sacc_mask[pairs[opt][1-isrc]]:\n",
    "                            continue\n",
    "\n",
    "                        match_ifix, match_other_ifix = pair_ifixs[1-isrc][[ofix,1-ofix]]\n",
    "\n",
    "                        # matched fixation must have the same categorization\n",
    "                        # (in addition to being return-paired)\n",
    "                        try:\n",
    "                            row = cat_df.loc[(igroup, match_ifix)]\n",
    "                            check = row[f'Is {match_cat}']\n",
    "                        except KeyError:\n",
    "                            check = False\n",
    "                        if not check:\n",
    "                            continue\n",
    "\n",
    "                        # non-matched fixation must have different categorization\n",
    "                        try:\n",
    "                            row = cat_df.loc[(igroup, match_other_ifix)]\n",
    "                            check = not row[f'Is {match_other_cat}']\n",
    "                        except KeyError:\n",
    "                            check = False  # alright if no category for other fix\n",
    "                        if not check:\n",
    "                            continue\n",
    "\n",
    "                        # non-matched fixation must not be close by\n",
    "                        match_xy, match_other_xy = fix_df.iloc[[match_ifix, match_other_ifix]][['Relative X', 'Relative Y']].values\n",
    "                        if np.linalg.norm(src_other_xy - match_other_xy) < min_sep:\n",
    "                            continue\n",
    "\n",
    "                        matched[i] = True\n",
    "                        match_isaccs[i] = pairs[opt,1-isrc]\n",
    "                        break\n",
    "\n",
    "                matched_frac.append(matched)\n",
    "                assert (match_isaccs[matched] >= 0).all()  # not using uint because pandas doesn't play well with it\n",
    "                df_out = pd.DataFrame(\n",
    "                    data={'Match saccade index': match_isaccs[matched]},\n",
    "                    index=df2.index[matched])\n",
    "                df_out['Group'] = igroup\n",
    "                match_sacc_df.append(df_out)\n",
    "\n",
    "        byscond_bytest_match_sacc_df[scond][test] = pd.concat(match_sacc_df)\n",
    "        print(scond, 'saccades, test:', test)\n",
    "        m = np.concatenate(matched_frac)\n",
    "        print(f'fraction of matched saccades matched: {m.mean()*1e2:.2f}% ({m.sum()} of {m.size})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ba6d72-92ac-4ac4-9446-5d91602feb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(analysis_name+'/saccade_selection/fixation_indices', sacc_sel)\n",
    "save_results(analysis_name+'/saccade_selection/large/saccade_subset', lg_sacc_mask)\n",
    "\n",
    "for scond, sacc_cat_dfs in byscond_sacc_cat_dfs.items():\n",
    "    group = analysis_name + '/by_saccade_size/' + scond + '/'\n",
    "    kwargs = dict(mode='a', format='table', complevel=9, complib='zlib')\n",
    "\n",
    "    sacc_cat_dfs.to_hdf(output_path, group+'saccade_categorization', **kwargs)\n",
    "    for itest, test in enumerate(match_tests):\n",
    "        byscond_bytest_match_sacc_df[scond][test].to_hdf(\n",
    "            output_path, group+'match_saccades/'+str(test), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d8ed04-e595-483f-84e0-5dbbaac85208",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6998be-d47a-45e6-a417-5aa876e9b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scond, sacc_cat_df in byscond_sacc_cat_dfs.items():\n",
    "    for test in match_tests:\n",
    "        match_sacc_df = byscond_bytest_match_sacc_df[scond][test]\n",
    "        ofix = ['previous', 'current'].index(test[1])\n",
    "        match_cat = test[0][ofix].lower()  # category of matched fixation\n",
    "        match_other_cat = test[0][1-ofix].lower()  # category of the other fixation in sacc\n",
    "\n",
    "        for igroup, mdf in tqdm(match_sacc_df.groupby('Group')):\n",
    "            df1 = sacc_cat_df[sacc_cat_df['Group']==igroup]\n",
    "\n",
    "            src_ifixs = df1.loc[mdf.index][['Fix 1 index', 'Fix 2 index']].values  # (n, 2)\n",
    "            match_ifixs = sacc_sel[:,mdf['Match saccade index'].values].T  # (n, 2)\n",
    "\n",
    "            # zeroth fixations should not be included\n",
    "            assert not (fix_ords[src_ifixs[:,0]] == 0).any()\n",
    "            assert not (fix_ords[match_ifixs[:,0]] == 0).any()\n",
    "\n",
    "            # matched fixations must be close\n",
    "            src_xys = fix_df.iloc[src_ifixs[:,ofix]][['Relative X', 'Relative Y']].values  # (n, 2)\n",
    "            match_xys = fix_df.iloc[match_ifixs[:,ofix]][['Relative X', 'Relative Y']].values  # (n, 2)\n",
    "            assert (return_thres >= np.linalg.norm(src_xys - match_xys, axis=-1)).all()\n",
    "\n",
    "            # non-matched fixations must be far\n",
    "            src_other_xys = fix_df.iloc[src_ifixs[:,1-ofix]][['Relative X', 'Relative Y']].values  # (n, 2)\n",
    "            match_other_xys = fix_df.iloc[match_ifixs[:,1-ofix]][['Relative X', 'Relative Y']].values  # (n, 2)\n",
    "            assert (min_sep <= np.linalg.norm(src_other_xys - match_other_xys, axis=-1)).all()\n",
    "\n",
    "            # matched category must be same\n",
    "            idc = pd.MultiIndex.from_arrays([np.full(len(match_ifixs),igroup), src_ifixs[:,ofix]])\n",
    "            src_cat = cat_df[f'Is {match_cat}'].reindex(idc).values\n",
    "            # may have duplicate indices so cannot use .loc\n",
    "            idc = pd.MultiIndex.from_arrays([np.full(len(match_ifixs),igroup), match_ifixs[:,ofix]])\n",
    "            match_cat_ = cat_df[f'Is {match_cat}'].reindex(idc).values\n",
    "            assert src_cat.all() and match_cat_.all()\n",
    "\n",
    "            # non-matched category must be different\n",
    "            idc = pd.MultiIndex.from_arrays([np.full(len(match_ifixs),igroup), src_ifixs[:,1-ofix]])\n",
    "            src_cat = cat_df[f'Is {match_other_cat}'].reindex(idc).values\n",
    "            idc = pd.MultiIndex.from_arrays([np.full(len(match_ifixs),igroup), match_ifixs[:,1-ofix]])\n",
    "            match_cat_ = cat_df[f'Is {match_other_cat}'].reindex(idc, fill_value=False).values\n",
    "            assert src_cat.all() and not match_cat_.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313c97aa-c75f-4575-b7e3-e81affe67f64",
   "metadata": {},
   "source": [
    "# Load neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75279c88-f982-465b-93c2-2422a8b1d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(sdf_path, 'r') as f:\n",
    "    dset = f['sdf']\n",
    "    all_unit_names = list(dset.attrs['unit_names'].astype(str))\n",
    "    sel_ = np.array([all_unit_names.index(n) for n in unit_names])\n",
    "    sdf = dset[()][:,sel_]\n",
    "\n",
    "n_neur = len(unit_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a140252-0910-40b9-950d-918d2c621950",
   "metadata": {},
   "source": [
    "# Across-saccade analysis: PSTHs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b101f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "byscond_psth_mean_std = {}\n",
    "byscond_pvals = {}\n",
    "byscond_nsaccs = {}\n",
    "ts = np.arange(-t_pre, t_post+t_step/10, t_step)\n",
    "\n",
    "for scond, sacc_cat_df in byscond_sacc_cat_dfs.items():\n",
    "    n_test = len(match_tests)\n",
    "    # shape (n_test, src/match, mean/std, time, unit)\n",
    "    byscond_psth_mean_std[scond] = psth_mean_std = \\\n",
    "        np.full((n_test, 2, 2, ts.size, n_neur), np.nan, dtype=sdf.dtype)\n",
    "    # shape (n_test, time, unit)\n",
    "    byscond_pvals[scond] = pvals = \\\n",
    "        np.full((n_test, ts.size, n_neur), np.nan, dtype=sdf.dtype)\n",
    "    byscond_nsaccs[scond] = nsaccs = np.zeros((n_test, n_neur), dtype=int)\n",
    "\n",
    "    for itest, test in enumerate(match_tests):\n",
    "        match_sacc_df = byscond_bytest_match_sacc_df[scond][test]\n",
    "\n",
    "        for igroup, df1_ in tqdm(sacc_cat_df.groupby('Group')):\n",
    "            mdf = match_sacc_df[match_sacc_df['Group']==igroup]\n",
    "            assert not any(df.index.has_duplicates for df in (df1_, mdf))\n",
    "            df1 = df1_.loc[mdf.index]\n",
    "            usel = unit_groups[igroup]\n",
    "\n",
    "            n_sacc = len(mdf)\n",
    "            paired_psths = np.empty((2, n_sacc, ts.size, usel.size), dtype=sdf.dtype)\n",
    "            for j, ifix2s in enumerate((\n",
    "                    df1['Fix 2 index'].values,\n",
    "                    sacc_sel[0,mdf['Match saccade index'].values]\n",
    "            )):\n",
    "                for i, t in enumerate(fix_df.iloc[ifix2s]['Time'].values):\n",
    "                    ts_ = np.round(t+ts).astype(int)\n",
    "                    # if not i: print(ts_)\n",
    "                    paired_psths[j,i] = sdf[ts_,:][:,usel]\n",
    "            psth_mean_std[itest,:,0,:,usel] = paired_psths.mean(1).transpose(2,0,1)  # transpose due to\n",
    "            psth_mean_std[itest,:,1,:,usel] = paired_psths.std(1).transpose(2,0,1)   # numpy indexing weirdness\n",
    "            nsaccs[itest,usel] = n_sacc\n",
    "\n",
    "            if n_sacc < 2:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                pvals[itest,:,usel] = st.wilcoxon(\n",
    "                    *paired_psths,\n",
    "                    alternative=test[2],\n",
    "                    axis=0\n",
    "                ).pvalue.T  # transpose due to numpy indexing weirdness\n",
    "            except ValueError as e:\n",
    "                if 'x - y is zero for all elements' not in str(e):\n",
    "                    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af8336-16ae-485e-9406-f18c02c5167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = np.array(('test', 'cond', 'statistic', 'time', 'unit'))\n",
    "coords = {\n",
    "    'test': np.array([str(v) for v in match_tests]),\n",
    "    'cond': np.array(('Original', 'Match')),\n",
    "    'statistic': np.array(['mean', 'std']),\n",
    "    'time': ts,\n",
    "    'unit': unit_names}\n",
    "compr = dict(compression='gzip', compression_opts=9)\n",
    "\n",
    "for scond, psth_mean_std in byscond_psth_mean_std.items():\n",
    "    group = analysis_name + f'/by_saccade_size/{scond}/'\n",
    "    pvals = byscond_pvals[scond]\n",
    "    nsaccs =  byscond_nsaccs[scond]\n",
    "    data_vars = {\n",
    "        'data': (dims, psth_mean_std),\n",
    "        'p-value': (dims[[0,-2,-1]], pvals),\n",
    "        'n_sacc': (dims[[0,-1]], nsaccs)}\n",
    "    dataset = xr.Dataset(data_vars, coords=coords)\n",
    "    dataset['data'].attrs.update({'unit': 'spikes/s'})\n",
    "\n",
    "    encoding = {\n",
    "        k: dict(chunksizes=v.shape, **compr) if v.size else {}\n",
    "        for k, v in dataset.data_vars.items()}\n",
    "    dataset.to_netcdf(\n",
    "        output_path, group=group+'psth',\n",
    "        mode='a', engine='h5netcdf', encoding=encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ad216-13f2-461a-af8d-ce940ef0ef18",
   "metadata": {},
   "source": [
    "# Wrap up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50b16a-744e-4328-9cbc-5813d8baed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(f'progress_report/{analysis_name}/all_done', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e15c0-cf86-4e73-860d-b55bafb4bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark -vm --iversions -rbg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a85c9-937e-4470-9f4e-c37cbff4490e",
   "metadata": {},
   "source": [
    "# Basic visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e848d575-0fd0-4f98-8f4a-96ca0aeab145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf62d99-6267-41ce-b9ec-20554fb215ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x if isinstance(x, str) else ', '.join(map(str, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12319f0-6405-4e86-83d5-a709ef11f846",
   "metadata": {},
   "source": [
    "### Quality control of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fbd507-1406-430e-a26a-2096c6945303",
   "metadata": {},
   "outputs": [],
   "source": [
    "sacc_xy1s = fix_df.iloc[sacc_sel[0]][['Relative X', 'Relative Y']].values\n",
    "sacc_xy2s = fix_df.iloc[sacc_sel[1]][['Relative X', 'Relative Y']].values\n",
    "fix_xys = fix_df[['Relative X', 'Relative Y']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2abf31-614b-4dbe-a876-c6b4a55d870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scond, sacc_cat_df in byscond_sacc_cat_dfs.items():\n",
    "    for itest, test in enumerate(match_tests):\n",
    "        ofix = ['previous', 'current'].index(test[1])\n",
    "\n",
    "        # tally all matches across units\n",
    "        match_sacc_df = byscond_bytest_match_sacc_df[scond][test]\n",
    "        if not match_sacc_df.size: continue\n",
    "        matches = set()  # set of tuples: (src_ifix1, src_ifix2, matcH_isacc)\n",
    "        for igroup, df1_ in tqdm(sacc_cat_df.groupby('Group')):\n",
    "            mdf = match_sacc_df[match_sacc_df['Group']==igroup]\n",
    "            df1 = df1_.loc[mdf.index]\n",
    "            for (_, row), (_, mrow) in zip(df1.iterrows(), mdf.iterrows()):\n",
    "                matches.add((row['Fix 1 index'], row['Fix 2 index'], mrow['Match saccade index']))\n",
    "\n",
    "        # plot matches aligned to src matched fix\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12,3.75))\n",
    "        plt.subplots_adjust(wspace=0.25)\n",
    "        fig.suptitle(f'Test: {f(test[0])} {dict(less=\"<\",greater=\">\").get(test[2],\"!=\")} match {f(test[1])}; Source saccades: {scond}', y=1)\n",
    "\n",
    "        sacc_sizes = []\n",
    "        d_match_nonmatched = []\n",
    "        for ii, (src_ifix1, src_ifix2, match_isacc) in enumerate(matches):\n",
    "            xy1 = fix_xys[src_ifix1]\n",
    "            xy2 = fix_xys[src_ifix2]\n",
    "            mxy1 = sacc_xy1s[match_isacc]\n",
    "            mxy2 = sacc_xy2s[match_isacc]\n",
    "\n",
    "            v = xy2 - xy1\n",
    "            mv = mxy2 - mxy1\n",
    "            dm0 = mxy1 - xy1\n",
    "\n",
    "            a = -np.arctan2(v[1], v[0])\n",
    "            sina = np.sin(a)\n",
    "            cosa = np.cos(a)\n",
    "            R = np.array([[cosa, -sina], [sina, cosa]]).T\n",
    "            rv = v @ R\n",
    "            rmv = mv @ R\n",
    "            rdm0 = dm0 @ R\n",
    "\n",
    "            for i in range(2):\n",
    "                offset = -rv if i else 0\n",
    "                axs[i].plot(*(rdm0+offset+(np.array([[0,0],rmv]))).T, c='k', alpha=.2)\n",
    "                axs[i].scatter(*(rdm0+offset), fc='k', ec='none', s=5, label=('FP 1',None)[(i!=ofix)&(ii>0)])  # match sacc start\n",
    "                axs[i].scatter(*(rdm0+offset+rmv), ec='b', fc='none', s=5, label=('FP 2',None)[(i!=ofix)&(ii>0)])  # match sacc end\n",
    "\n",
    "            sacc_sizes.append(np.linalg.norm(v))\n",
    "            d_match_nonmatched.append(np.linalg.norm((xy2,xy1)[ofix]-(mxy1,mxy2)[ofix]))\n",
    "\n",
    "        x, y = sacc_sizes, d_match_nonmatched\n",
    "        axs[2].scatter(x, y, s=10)\n",
    "        b = np.array([x,y])\n",
    "        if b.size:\n",
    "            b0, b1 = b.min(1).max(0), b.max(1).min(0)\n",
    "            axs[2].plot([b0,b1], [b0,b1], color='gray', ls='--')\n",
    "            axs[2].plot([b0,b1+return_thres], [b0-return_thres, b1], color='gray', ls=':')\n",
    "        axs[2].set_xlabel('Source saccade size, dva')\n",
    "        axs[2].set_ylabel('Distance, match to source nonmatched, dva')\n",
    "\n",
    "        for i in range(2):\n",
    "            if i == ofix:\n",
    "                e = mpl.patches.Ellipse([0,0], 2*return_thres, 2*return_thres, ec='k', fc='none')\n",
    "            else:\n",
    "                e = mpl.patches.Ellipse([0,0], 2*min_sep, 2*min_sep, ec='r', fc='none')\n",
    "            axs[i].add_artist(e)\n",
    "            axs[i].set_title(f'Match FP {ofix+1}, aligned to FP {i+1}')\n",
    "            if i != ofix:\n",
    "                axs[i].legend()\n",
    "            axs[i].set_xlabel('Pos. along saccade, dva')\n",
    "            axs[i].set_ylabel('Pos. in orth. direction, dva')\n",
    "\n",
    "        for ax in axs:\n",
    "            ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98044c5-9529-4072-b652-5a4ba4bfd9f6",
   "metadata": {},
   "source": [
    "### Two-category PSTHs across saccades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scond, bytest_psth_mean_std in byscond_psth_mean_std.items():\n",
    "    if not np.isfinite(bytest_psth_mean_std).any(): continue\n",
    "    n = len(match_tests)\n",
    "    fig, axs = plt.subplots(1, n, figsize=(4*n,3), squeeze=False)\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    axs = axs.ravel()\n",
    "    for itest, psth_mean_std in enumerate(bytest_psth_mean_std):\n",
    "        ax = axs[itest]\n",
    "        test = match_tests[itest]\n",
    "        nsaccs = byscond_nsaccs[scond][itest]\n",
    "        for i in range(2):\n",
    "            m = np.nanmean(psth_mean_std[i, 0], 1)\n",
    "            s = np.nanstd(psth_mean_std[i, 0], 1)\n",
    "            if i:\n",
    "                lbl = f'Match {test[1]}'\n",
    "            else:\n",
    "                mn = nsaccs.mean()\n",
    "                sn = nsaccs.std()\n",
    "                lbl = r'$\\rightarrow$'.join(test[0]) + f' ({mn:.1f}+/-{sn:.1f})'\n",
    "            ax.plot(ts, m, label=lbl)\n",
    "        ax.legend(fontsize=8)\n",
    "    axs[0].set_xlabel('Time rel. fix. on, ms')\n",
    "    axs[0].set_ylabel('Grand mean FR, spks/s')\n",
    "    fig.suptitle(scond.capitalize() + ' saccades')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2720b28-935e-44d9-8f0f-e334a33a66a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scond, pvals in byscond_pvals.items():\n",
    "    if not np.isfinite(pvals).any(): continue\n",
    "    n = len(pvals)\n",
    "    fig, axs = plt.subplots(1, n, figsize=(4*n,3), squeeze=False)\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    axs = axs.ravel()\n",
    "    f = lambda x: x if isinstance(x, str) else ', '.join(map(str, x))\n",
    "    for i, ax in enumerate(axs):\n",
    "        vs = pvals[i]\n",
    "        ax.plot(ts, pvals[i], c='k', lw=0.5);\n",
    "        ax.set_yscale('log')\n",
    "        ax.hlines(1e-2, ts.min(), ts.max(), ls='--', lw=0.5, color='r')\n",
    "        ax.text(.05, .05, f'{f(test[0])} {dict(less=\"<\",greater=\">\").get(test[2],\"!=\")}\\nmatch {f(test[1])}',\n",
    "                ha='left', va='bottom', transform=ax.transAxes, fontsize=8)\n",
    "    fig.suptitle(scond.capitalize() + ' saccades')\n",
    "    axs[0].set_xlabel('Time rel. fix. on, ms')\n",
    "    axs[0].set_ylabel('P-value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
