{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee8967d-d61e-45a9-a66c-1cb061efba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "sys.path.append('../lib')\n",
    "from storage import get_storage_functions, quantize\n",
    "from local_paths import preproc_dir, analysis_dir, database_dir\n",
    "from self_consistency import find_return_fixations, pairwise_self_consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a6ab8-2254-4096-861d-950ec7dbe326",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d49c84-3790-4c27-95f8-1c6c13585d9b",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# session\n",
    "#============================================================================\n",
    "sess_name = 'sess_name'\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# response windows\n",
    "#============================================================================\n",
    "t_win = 200\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# return fixation selection\n",
    "#============================================================================\n",
    "return_thres_opts = (1/16, 1/8, 1/4, 1/2, 1, 2, 4, 8, 16)\n",
    "exclude_same_trial = True\n",
    "\n",
    "# \"decorrelate\" return fixations:\n",
    "#   sub-select only return pairs where the non-return fixations\n",
    "#   (e.g., \"prev\" for \"curr return\") are this far apart\n",
    "min_sep      =   4  # dva; only consider saccades at least this large\n",
    "min_sep_win  = 100\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# paths\n",
    "#============================================================================\n",
    "proc_dir = preproc_dir\n",
    "output_dir = analysis_dir + 'rsc_precision'\n",
    "\n",
    "latency_path = database_dir + 'per_unit_latency-fix_on.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fee6e67-4c83-4a27-8122-52971dcca58b",
   "metadata": {},
   "source": [
    "# Check prereqs and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed4397-6992-49f9-ae8d-b1b3348cbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_path = Path(proc_dir) / (sess_name + '-proc.h5')\n",
    "print('Loading shared processing from', proc_path)\n",
    "proc_path = proc_path.expanduser()\n",
    "assert proc_path.is_file()\n",
    "\n",
    "rasters_path = Path(proc_dir) / (sess_name + '-rasters.nwb')\n",
    "print('Loading rasters from', rasters_path)\n",
    "rasters_path = rasters_path.expanduser()\n",
    "assert rasters_path.is_file()\n",
    "\n",
    "print('Using per-unit latency from', latency_path)\n",
    "latency_path = Path(latency_path).expanduser()\n",
    "assert latency_path.is_file()\n",
    "\n",
    "output_dir = Path(output_dir)\n",
    "assert output_dir.expanduser().is_dir()\n",
    "output_path = output_dir / (sess_name + '.h5')\n",
    "print('Saving results to', output_path)\n",
    "output_path = output_path.expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc501691-4e8d-40e3-8d7a-9d39a5187fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'rsc_precision'\n",
    "\n",
    "if output_path.is_file():\n",
    "    with h5.File(output_path, 'r') as f:\n",
    "        try:\n",
    "            if f[f'progress_report/{analysis_name}/all_done'][()].item():\n",
    "                raise RuntimeError(f'{sess_name} has already been processed')\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ebcbec-d4e7-408c-ac5d-d710117c24b6",
   "metadata": {},
   "source": [
    "# Save config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd7a35a-cdb9-477d-9ede-6261a242e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(proc_path, 'r') as f:\n",
    "    random_seed = f['config/default_random_seed'][()]\n",
    "    sacc_sel = f['saccade_selection/fixation_indices'][()]\n",
    "    unit_names = f['unit_selection/simple'][()].astype(str)\n",
    "fix_df = pd.read_hdf(proc_path, 'fixation_dataframe', 'r')\n",
    "\n",
    "print('random_seed:', random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1fec9f-dafe-4a78-b57d-dd407ccfe202",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results, add_attr_to_dset, check_equals_saved, link_dsets, copy_group = \\\n",
    "    get_storage_functions(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00871c-e19c-4e6c-bbc4-a7bec3c1dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = analysis_name + '/config/'\n",
    "save_results(group+'random_seed', random_seed)\n",
    "save_results(f'{group}/return_thres_options', np.array(return_thres_opts), attrs=dict(unit='dva'))\n",
    "save_results(f'{group}/exclude_same_trial', exclude_same_trial)\n",
    "\n",
    "group = analysis_name + '/config/time_windows/'\n",
    "save_results(group+'t_win', t_win)\n",
    "add_attr_to_dset(group, attrs=dict(unit='ms'))\n",
    "\n",
    "group = analysis_name + '/config/return_criterion/'\n",
    "save_results(f'{group}/return_thres_options', np.array(return_thres_opts), attrs=dict(unit='dva'))\n",
    "save_results(group+'min_sep', min_sep, attrs=dict(unit='dva'))\n",
    "save_results(group+'min_sep_win', min_sep_win, attrs=dict(unit='ms'))\n",
    "\n",
    "save_results(analysis_name+'/saccade_selection', sacc_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c29c11-21b5-4677-a066-75f19ec221c6",
   "metadata": {},
   "source": [
    "# Find return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ab737-8e14-47ea-9fba-415c92b634b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorrelate_return_pairs(return_pairs, cond='current', min_sep=min_sep, min_sep_win=min_sep_win, fix_df=fix_df):\n",
    "    decorr_win = 'current' if cond == 'previous' else 'previous'\n",
    "\n",
    "    iind_tr = fix_df.index.names.index('Trial')\n",
    "    iind_fix = fix_df.index.names.index('Fixation')\n",
    "\n",
    "    min_seps = np.full(len(return_pairs), np.inf)\n",
    "\n",
    "    for i, (i0_, i1_) in enumerate(return_pairs):\n",
    "        i0, i1 = sacc_sel[1,[i0_,i1_]]\n",
    "        itr0, itr1 = fix_df.index.get_level_values(iind_tr)[[i0,i1]]\n",
    "        tr0_fixs = fix_df.loc[(itr0, slice(None))]\n",
    "        tr1_fixs = fix_df.loc[(itr1, slice(None))]\n",
    "\n",
    "        # find any relevant fixations within min_sep window\n",
    "        if decorr_win == 'current':\n",
    "            ifix0, ifix1 = fix_df.index.get_level_values(iind_fix)[[i0,i1]]\n",
    "            t0, t1 = fix_df.iloc[[i0,i1]]['Time'].values\n",
    "\n",
    "            m0 = tr0_fixs.index >= ifix0\n",
    "            if not m0.any(): continue\n",
    "            m0[m0] = tr0_fixs.loc[m0, 'Time'] <= (t0 + min_sep_win)\n",
    "            if not m0.any(): continue\n",
    "\n",
    "            m1 = tr1_fixs.index >= ifix1\n",
    "            if not m1.any(): continue\n",
    "            m1[m1] = tr1_fixs.loc[m1, 'Time'] <= (t1 + min_sep_win)\n",
    "            if not m1.any(): continue\n",
    "\n",
    "        else:\n",
    "            i0, i1 = sacc_sel[0,[i0_,i1_]]\n",
    "            ifix0, ifix1 = fix_df.index.get_level_values(iind_fix)[[i0,i1]]\n",
    "            t0, t1 = fix_df.iloc[[i0,i1]]['End time'].values\n",
    "\n",
    "            m0 = tr0_fixs.index <= ifix0\n",
    "            if not m0.any(): continue\n",
    "            m0[m0] = tr0_fixs.loc[m0, 'End time'].values > (t0 - min_sep_win)\n",
    "            if not m0.any(): continue\n",
    "\n",
    "            m1 = tr1_fixs.index <= ifix1\n",
    "            if not m1.any(): continue\n",
    "            m1[m1] = tr1_fixs.loc[m1, 'End time'].values > (t1 - min_sep_win)\n",
    "            if not m1.any(): continue\n",
    "\n",
    "        pwd = np.linalg.norm(\n",
    "            tr0_fixs.loc[m0, ['Relative X', 'Relative Y']].values[:,None,:]\n",
    "            - tr1_fixs.loc[m1, ['Relative X', 'Relative Y']].values[None,:,:],\n",
    "            axis=-1)\n",
    "        min_seps[i] = pwd.min()\n",
    "\n",
    "    return return_pairs[min_seps >= min_sep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af4559-ca65-49fa-970e-adddd42401aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = fix_df.iloc[sacc_sel[1]]\n",
    "imids = np.array([f'{v0}/{v1}' for v0, v1 in df_[['Image subdir', 'Image filename']].values])\n",
    "posns = df_[['Relative X', 'Relative Y']].values\n",
    "\n",
    "\n",
    "# first, find returns at the highst threshold; this is the superset of return pairs at all thresholds\n",
    "return_thres = np.max(return_thres_opts)\n",
    "return_pairs = find_return_fixations(imids, posns, thres_deg=return_thres)\n",
    "print(f'return_thres: 2^{np.log2(return_thres):.1f}', end=';\\t')\n",
    "print('return pairs:', return_pairs.shape, end=';\\t')\n",
    "\n",
    "if min_sep > 0:\n",
    "    return_pairs = decorrelate_return_pairs(return_pairs)\n",
    "    print(f'decorrelated:', return_pairs.shape, end=';\\t')\n",
    "\n",
    "if exclude_same_trial:\n",
    "    fix_itrs = fix_df.index.get_level_values(fix_df.index.names.index('Trial')).values[sacc_sel[1]]\n",
    "    m = fix_itrs[return_pairs[:,0]] != fix_itrs[return_pairs[:,1]]\n",
    "    return_pairs = return_pairs[m]\n",
    "    print('excluded same-trial:', return_pairs.shape, end='')\n",
    "\n",
    "print()\n",
    "all_return_pairs = return_pairs\n",
    "pwd = np.linalg.norm(posns[return_pairs[:,0]] - posns[return_pairs[:,1]], axis=1)\n",
    "\n",
    "\n",
    "# next, subselect pairs per threshold\n",
    "bycond_return_pairs = {}\n",
    "bycond_pairs_subsel = {}\n",
    "for return_thres in return_thres_opts:\n",
    "    m = pwd <= return_thres\n",
    "    k = str(return_thres)\n",
    "    bycond_return_pairs[k] = return_pairs[m]\n",
    "    bycond_pairs_subsel[k] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac2a8e5-5329-41df-8e9d-d7d7dbde0e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(analysis_name+'/all_return_pairs', all_return_pairs)\n",
    "\n",
    "group = analysis_name + '/return_pairs_subset/'\n",
    "for cond, subsel in bycond_pairs_subsel.items():\n",
    "    save_results(group+cond, subsel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af17c0-7522-4240-95fa-2c66b681e974",
   "metadata": {},
   "source": [
    "# Get fixation onset-aligned responses uaing latency per unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1fe8bf-847e-406b-871f-26e83c80a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(rasters_path, 'r') as f:\n",
    "    all_unit_names = f['processing/ecephys/unit_names/unit_name'][()].astype(str)\n",
    "    all_unit_names = list(all_unit_names)\n",
    "    sel_ = np.array([all_unit_names.index(n) for n in unit_names])\n",
    "    rasters = f['processing/ecephys/rasters/data'][()][:,sel_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef1945-fb0f-4cbe-b53a-8d4ec6834c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_df = pd.read_csv(latency_path).set_index('Session').loc[[sess_name]].set_index('Name')\n",
    "m = pd.Series(unit_names).isin(lat_df.index)\n",
    "assert m.all(), f'missing latency value for {(~m).sum()} of {m.size} units'\n",
    "assert not lat_df.index.has_duplicates\n",
    "\n",
    "lat_df = lat_df.loc[unit_names].reset_index()\n",
    "assert len(lat_df) == len(unit_names)\n",
    "lat_df['Index'] = np.arange(len(lat_df))\n",
    "lat_df['Latency'] = np.clip(lat_df['Latency'], 40, None)\n",
    "print('Num units using RF fit from each source:')\n",
    "print('\\t' + '\\n\\t'.join(str(lat_df.groupby('Source').count()['Latency']).split('\\n')[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b2c98-9ebd-487b-9b04-8b6932554661",
   "metadata": {},
   "outputs": [],
   "source": [
    "resps = np.empty((sacc_sel.shape[1], rasters.shape[1]), dtype=np.float32)\n",
    "t_win_ = np.array([0, t_win])\n",
    "lat_groups = [(dt, df_['Index'].values) for dt, df_ in lat_df.groupby('Latency')]\n",
    "for i, t in enumerate(fix_df.iloc[sacc_sel[1]]['Time'].values):\n",
    "    for dt, usel in lat_groups:\n",
    "        s = slice(*np.round(t+dt+t_win_).astype(int))\n",
    "        resps[i,usel] = rasters[s,usel].mean(0)\n",
    "\n",
    "resps.shape, resps.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f615492a-e8ad-4732-9166-0cbb4f7e3bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_df.to_hdf(output_path, analysis_name+'/latency_per_unit', mode='a', format='table', complevel=9, complib='zlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e000f69-4a4f-41f6-97bf-1962a39f7931",
   "metadata": {},
   "source": [
    "# Calculate return self-consistency (one-point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70cc74-cc6d-4c9d-a7ff-ed149fb41fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = (('unit', unit_names),)\n",
    "\n",
    "bycond_rsc_ds = {}\n",
    "for cond, pairs in bycond_return_pairs.items():\n",
    "    pairs = bycond_return_pairs[cond]\n",
    "    if len(pairs) > 1:\n",
    "        ds = pairwise_self_consistency(\n",
    "            pairs=pairs, resps=resps,\n",
    "            n_bootstraps=0, n_permutations=0,\n",
    "            random_seed=random_seed,\n",
    "            coords=coords)\n",
    "        ds = ds.assign(dict(n_pairs=len(pairs)))\n",
    "        bycond_rsc_ds[cond] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b6610-e3c2-4ba6-a309-568297b63011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat datasets along new dimension\n",
    "ks = np.array(list(bycond_rsc_ds.keys()))\n",
    "if len(ks):\n",
    "    idc = np.array(list(map(float, ks)))\n",
    "    so = np.argsort(idc)\n",
    "    idc = idc[so]\n",
    "    ks = ks[so]\n",
    "    dim = pd.Index(data=idc, name='return_thres')\n",
    "    dataset = xr.concat([bycond_rsc_ds[k] for k in ks], dim, coords='all')\n",
    "    dataset.attrs = {}\n",
    "else:\n",
    "    dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a935c-c099-42e7-aa4b-f8c338d8206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = analysis_name + '/data'\n",
    "\n",
    "if dataset is not None:\n",
    "    q = lambda x: quantize(x, 3)\n",
    "    compr = dict(zlib=True, complevel=9)\n",
    "    k = 'sample'\n",
    "    dataset = dataset.assign({k: q(dataset.data_vars[k])})\n",
    "    encoding = {\n",
    "        k: dict(chunksizes=v.shape, **compr)\n",
    "        for k, v in dataset.data_vars.items()\n",
    "        if v.size}\n",
    "    dataset.to_netcdf(\n",
    "        output_path, group=loc, mode='a',\n",
    "        engine='h5netcdf', encoding=encoding)\n",
    "else:\n",
    "    save_results(loc, h5.Empty('f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa9be60-8143-4c25-9acb-375b5d5ee10e",
   "metadata": {},
   "source": [
    "# Wrap up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641e878-8432-42a6-957b-21e1a410b3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(f'progress_report/{analysis_name}/all_done', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f87da-04c7-42e9-ac72-63c277b5282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark -vm --iversions -rbg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59467d70-20d4-406f-be54-ad42421467fc",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb46fb0-4641-412c-8bc6-cfabd2d5e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce9e59-0ae9-4e24-b484-6102814d6829",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset is not None:\n",
    "    vs = dataset['sample'].values\n",
    "    m = np.nanmedian(vs, axis=1)\n",
    "    s = np.nanmedian(np.abs(vs - m[:,None]))\n",
    "    x = dataset['return_thres'].values\n",
    "    plt.plot(x, m, '.-')\n",
    "    plt.fill_between(x, m-s, m+s, alpha=0.2);\n",
    "    plt.xscale('log', base=2)\n",
    "    plt.xlabel('Return fixation threshold, dva')\n",
    "    plt.ylabel('Self-consistency, Pearson\\'s r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05e8b80-7788-4b21-8a3d-e958dc1c3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset is not None:\n",
    "    m = dataset['n_pairs'].values\n",
    "    x = dataset['return_thres'].values\n",
    "    plt.plot(x, m, '.-')\n",
    "    plt.xscale('log', base=2)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Return fixation threshold, dva')\n",
    "    plt.ylabel('Num. return pairs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
