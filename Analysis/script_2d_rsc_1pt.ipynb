{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b160df3e-1967-4335-8846-a4762f65b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../lib')\n",
    "from storage import get_storage_functions, quantize\n",
    "from local_paths import preproc_dir, analysis_dir, database_dir\n",
    "from self_consistency import \\\n",
    "    find_return_fixations, pairwise_self_consistency, \\\n",
    "    pairwise_self_consistency_perm_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e140cdf-f8bb-473d-8735-5184a9a4728c",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665fa7b-eb3d-4e06-97ce-d977627e2599",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# session\n",
    "#============================================================================\n",
    "sess_name = 'sess_name'\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# response windows\n",
    "#============================================================================\n",
    "t_win = 200\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# fixation/saccade selection\n",
    "#============================================================================\n",
    "# fixation criteria\n",
    "ifix_sel = 2  # 0 = zeroth-fix only; 1 = non-zeroth-fix only; otherwise = both\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# return fixation selection\n",
    "#============================================================================\n",
    "return_thres = 1  # for defining \"return fixation\"; can set to typical radius of rf\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# statistical tests\n",
    "#============================================================================\n",
    "stat_tests      = (('current', 'same_image', 'greater'),)\n",
    "n_perm          = 10000\n",
    "save_perm_diffs = False  # whether to save permuted delta effect sizes\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# paths\n",
    "#============================================================================\n",
    "proc_dir = preproc_dir\n",
    "latency_path = database_dir + 'per_unit_latency-fix_on.csv.gz'\n",
    "output_dir = analysis_dir + 'rsc_1pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde34193-e22c-4a85-a259-6b9aa595e8da",
   "metadata": {},
   "source": [
    "# Check prereqs and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed4397-6992-49f9-ae8d-b1b3348cbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_path = Path(proc_dir) / (sess_name + '-proc.h5')\n",
    "print('Loading shared processing from', proc_path)\n",
    "proc_path = proc_path.expanduser()\n",
    "assert proc_path.is_file()\n",
    "\n",
    "rasters_path = Path(proc_dir) / (sess_name + '-rasters.nwb')\n",
    "print('Loading rasters from', rasters_path)\n",
    "rasters_path = rasters_path.expanduser()\n",
    "assert rasters_path.is_file()\n",
    "\n",
    "print('Using per-unit latency from', latency_path)\n",
    "latency_path = Path(latency_path).expanduser()\n",
    "assert latency_path.is_file()\n",
    "\n",
    "output_dir = Path(output_dir)\n",
    "assert output_dir.expanduser().is_dir()\n",
    "output_path = output_dir / (sess_name + '.h5')\n",
    "print('Saving results to', output_path)\n",
    "output_path = output_path.expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc501691-4e8d-40e3-8d7a-9d39a5187fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'rsc_1pt'\n",
    "\n",
    "if output_path.is_file():\n",
    "    with h5.File(output_path, 'r') as f:\n",
    "        try:\n",
    "            if f[f'progress_report/{analysis_name}/all_done'][()].item():\n",
    "                raise RuntimeError(f'{sess_name} has already been processed')\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2126ea-53e6-4237-9300-6de70e517bb1",
   "metadata": {},
   "source": [
    "# Save config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd7a35a-cdb9-477d-9ede-6261a242e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_df = pd.read_hdf(proc_path, 'fixation_dataframe', 'r')\n",
    "\n",
    "with h5.File(proc_path, 'r') as f:\n",
    "    random_seed = f['config/default_random_seed'][()]\n",
    "    unit_names = f['unit_selection/simple'][()].astype(str)\n",
    "    fix_sel = f['fixation_selection/fixation_indices'][()]\n",
    "    if ifix_sel in (0, 1):\n",
    "        m = 0 == fix_df.index.get_level_values(fix_df.index.names.index('Fixation'))[fix_sel]\n",
    "        if ifix_sel == 1:\n",
    "            m = ~m\n",
    "        fix_sel = fix_sel[m]\n",
    "\n",
    "print('random_seed:', random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed9cde-c754-445e-baf4-fd966a8fc9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results, add_attr_to_dset, check_equals_saved, link_dsets, copy_group = \\\n",
    "    get_storage_functions(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21793eb7-9502-48e4-b45d-1cc62f52c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = analysis_name + '/config/'\n",
    "save_results(group+'random_seed', random_seed)\n",
    "save_results(group+'ifix_sel', ifix_sel)\n",
    "\n",
    "group = analysis_name + '/config/time_windows/'\n",
    "save_results(group+'t_win', t_win)\n",
    "add_attr_to_dset(group, attrs=dict(unit='ms'))\n",
    "\n",
    "group = analysis_name + '/config/return_criterion/'\n",
    "save_results(group+'return_thres', return_thres, attrs=dict(unit='dva'))\n",
    "\n",
    "group = analysis_name + '/config/statistics/'\n",
    "save_results(group+'tests', str(stat_tests))\n",
    "save_results(group+'test_kind', 'permutation')\n",
    "save_results(group+'n_perm', n_perm)\n",
    "\n",
    "save_results(analysis_name+'/fixation_selection', fix_sel)\n",
    "save_results(analysis_name+'/unit_names', unit_names.astype(bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74219c-d973-4613-b00c-fae225830b34",
   "metadata": {},
   "source": [
    "# Find return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844c114-3a76-434f-9978-b4f400443ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = fix_df.iloc[fix_sel]\n",
    "imids = np.array([f'{v0}/{v1}' for v0, v1 in df_[['Image subdir', 'Image filename']].values])\n",
    "posns = df_[['Relative X', 'Relative Y']].values\n",
    "\n",
    "curr_return_pairs = find_return_fixations(imids, posns, thres_deg=return_thres)\n",
    "same_image_return_pairs = find_return_fixations(imids, np.zeros_like(posns), thres_deg=return_thres)\n",
    "print('\"current\" return pairs shape:', curr_return_pairs.shape)\n",
    "print('\"same_image\" return pairs shape:', same_image_return_pairs.shape)\n",
    "\n",
    "bycond_return_pairs = dict(\n",
    "    current=curr_return_pairs,\n",
    "    same_image=same_image_return_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac2a8e5-5329-41df-8e9d-d7d7dbde0e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = analysis_name + '/return_pairs/'\n",
    "for cond, pairs in bycond_return_pairs.items():\n",
    "    if not pairs.size:\n",
    "        pairs = h5.Empty('i')\n",
    "    save_results(group+cond, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed53f001-d2f0-47f7-a5b3-59af43131e1c",
   "metadata": {},
   "source": [
    "# Get fixation onset-aligned responses uaing latency per unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff229b1-3adc-460b-ae7b-c21fa0c8da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(rasters_path, 'r') as f:\n",
    "    all_unit_names = f['processing/ecephys/unit_names/unit_name'][()].astype(str)\n",
    "    all_unit_names = list(all_unit_names)\n",
    "    sel_ = np.array([all_unit_names.index(n) for n in unit_names])\n",
    "    rasters = f['processing/ecephys/rasters/data'][()][:,sel_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840c9651-eb18-463b-b2fd-617de7bd8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_df = pd.read_csv(latency_path).set_index('Session').loc[[sess_name]].set_index('Name')\n",
    "m = pd.Series(unit_names).isin(lat_df.index)\n",
    "assert m.all(), f'missing latency value for {(~m).sum()} of {m.size} units'\n",
    "assert not lat_df.index.has_duplicates\n",
    "\n",
    "lat_df = lat_df.loc[unit_names].reset_index()\n",
    "assert len(lat_df) == len(unit_names)\n",
    "lat_df['Index'] = np.arange(len(lat_df))\n",
    "lat_df['Latency'] = np.clip(lat_df['Latency'], 40, None)\n",
    "print('Num units using RF fit from each source:')\n",
    "print('\\t' + '\\n\\t'.join(str(lat_df.groupby('Source').count()['Latency']).split('\\n')[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f7eb8-90d9-4a60-a556-da3bbbc31c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "resps = np.empty((fix_sel.size, rasters.shape[1]), dtype=np.float32)\n",
    "t_win_ = np.array([0, t_win])\n",
    "lat_groups = [(dt, df_['Index'].values) for dt, df_ in lat_df.groupby('Latency')]\n",
    "for i, t in enumerate(fix_df.iloc[fix_sel]['Time'].values):\n",
    "    for dt, usel in lat_groups:\n",
    "        s = slice(*np.round(t+dt+t_win_).astype(int))\n",
    "        resps[i,usel] = rasters[s,usel].mean(0)\n",
    "del rasters\n",
    "resps.shape, resps.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe775535-0d85-47cb-a4dd-012957b91aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_df.to_hdf(output_path, analysis_name+'/latency_per_unit', mode='a', format='table', complevel=9, complib='zlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de256eeb-efe7-4c84-bc34-264f3398492c",
   "metadata": {},
   "source": [
    "# One-condition permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abf977-2db0-4a90-bfa5-8ee1d5d6e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = (('unit', unit_names),)\n",
    "attrs = dict(\n",
    "    return_thres=return_thres,\n",
    "    random_seed=random_seed,\n",
    "    unit='Pearson\\'s r')\n",
    "\n",
    "bycond_rsc_ds = {}\n",
    "cond = 'current'\n",
    "pairs = bycond_return_pairs[cond]\n",
    "if len(pairs) > 1:\n",
    "    attrs['n_pairs'] = len(pairs)\n",
    "    ds = pairwise_self_consistency(\n",
    "        pairs=pairs, resps=resps,\n",
    "        n_bootstraps=0, n_permutations=n_perm,\n",
    "        random_seed=random_seed,\n",
    "        coords=coords, attrs=attrs)\n",
    "else:\n",
    "    ds = None\n",
    "bycond_rsc_ds[cond] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a935c-c099-42e7-aa4b-f8c338d8206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = analysis_name + '/'\n",
    "q = lambda x: quantize(x, 3)\n",
    "compr = dict(zlib=True, complevel=9)\n",
    "for cond, dataset in bycond_rsc_ds.items():\n",
    "    loc = group + cond\n",
    "    if dataset is not None:\n",
    "        if not save_perm_diffs:\n",
    "            dataset = dataset.drop_vars('permutations')\n",
    "        k = 'sample'\n",
    "        dataset = dataset.assign({k: q(dataset.data_vars[k])})\n",
    "        encoding = {\n",
    "            k: dict(chunksizes=v.shape, **compr)\n",
    "            for k, v in dataset.data_vars.items()\n",
    "            if v.size}\n",
    "        dataset.to_netcdf(\n",
    "            output_path, group=loc, mode='a',\n",
    "            engine='h5netcdf', encoding=encoding)\n",
    "    else:\n",
    "        save_results(loc, h5.Empty('f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4224f492-76a9-411e-903f-390a5a3c1747",
   "metadata": {},
   "source": [
    "# Two-condition permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0849522c-2dd1-4fe1-b8ec-d11cbf4dbad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "\n",
    "coords = (('unit', unit_names),)\n",
    "attrs = dict(random_seed=random_seed)\n",
    "\n",
    "for test in stat_tests:\n",
    "    c0, c1 = test[:2]\n",
    "    if len(test) > 2:\n",
    "        alt = test[2]\n",
    "    else:\n",
    "        alt = 'two-sided'\n",
    "    print('test:', (c0, c1), '\\talternative:', alt)\n",
    "\n",
    "    try:\n",
    "        ds = pairwise_self_consistency_perm_test(\n",
    "            resps=resps,\n",
    "            pairs0=bycond_return_pairs[c0],\n",
    "            pairs1=bycond_return_pairs[c1],\n",
    "            alternatives=alt,\n",
    "            n_permutations=n_perm,\n",
    "            random_seed=random_seed,\n",
    "            coords=coords,\n",
    "            attrs=attrs,\n",
    "            verbose=True)\n",
    "    except ValueError as e:\n",
    "        if 'Less than 2 pairs' in str(e):\n",
    "            continue\n",
    "        raise\n",
    "\n",
    "    test_results[(c0,c1)] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd141f-4168-47e4-a587-8175325bf406",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = analysis_name + '/permutation_test/'\n",
    "compr = dict(zlib=True, complevel=9)\n",
    "for (c0, c1), dataset in test_results.items():\n",
    "    if not save_perm_diffs:\n",
    "        dataset = dataset.drop_vars('permuted_diffs')\n",
    "    encoding = {\n",
    "        k: dict(chunksizes=v.shape, **compr)\n",
    "        for k, v in dataset.data_vars.items()\n",
    "        if v.size}\n",
    "    dataset.to_netcdf(\n",
    "        output_path, group=group+f'{c0}_v_{c1}',\n",
    "        mode='a', engine='h5netcdf', encoding=encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385f7a0a-6781-4348-9e26-694a111d40bc",
   "metadata": {},
   "source": [
    "# Wrap up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50b16a-744e-4328-9cbc-5813d8baed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(f'progress_report/{analysis_name}/all_done', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e15c0-cf86-4e73-860d-b55bafb4bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark -vm --iversions -rbg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8dd1d7-a313-46d4-b61d-00d5ede066af",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4edad97-3dfe-4d04-a342-cae13c230afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = lambda x: x if isinstance(x, str) else ', '.join(map(str, x))\n",
    "p_thres = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955458b-3de7-4df1-a510-374e62acca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_perm > 0:\n",
    "    cond = 'current'\n",
    "    dataset = bycond_rsc_ds[cond]\n",
    "    plt.figure()\n",
    "    x = dataset['p-value'].values.ravel()\n",
    "    sig = x < p_thres\n",
    "    plt.hist([np.log10(x[~sig]), np.log10(x[sig])], stacked=True, label=['Insig.','Sig.'])\n",
    "    plt.xlabel('P-value (log10)')\n",
    "    plt.ylabel('Num. neurons')\n",
    "    plt.legend()\n",
    "else:\n",
    "    sig = np.zeros(unit_names.size, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d1a9a-0bf7-472a-96d4-9b7e8946273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test, results in test_results.items():\n",
    "    plt.figure()\n",
    "    vals = np.array([results['cond0'], results['cond1']])\n",
    "    if n_perm > 0:\n",
    "        sig_ = results['p-value'].values.ravel() < p_thres\n",
    "    else:\n",
    "        sig_ = np.zeros(unit_names.size, dtype=bool)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            m = (sig^bool(i))&(sig_^bool(j))\n",
    "            if not m.any(): continue\n",
    "            c = ('tab:orange', 'tab:blue')[i]\n",
    "            if j:\n",
    "                kwargs = dict(ec=c, fc='none', marker='s')\n",
    "            else:\n",
    "                kwargs = dict(fc=c, ec='none', marker='o')\n",
    "            if i:\n",
    "                kwargs['label'] = 'Insig. RSC'\n",
    "            else:\n",
    "                kwargs['label'] = ('Sig', 'Insig.')[j] + ' '+ ' > '.join(test[:2])\n",
    "            plt.scatter(*vals[:,m], **kwargs)\n",
    "    b = np.ma.masked_invalid(vals)\n",
    "    b = [b.min(1).max(0), b.max(1).min(0)]\n",
    "    plt.plot(b, b, color='gray', ls='--')\n",
    "    plt.xlabel(test[0].capitalize())\n",
    "    plt.ylabel(test[1].capitalize())\n",
    "    plt.text(0, 1.025, f'Self-consistency, Pearson\\'s r\\nWindow size: {t_win} ms',\n",
    "              ha='left', va='bottom', transform=plt.gca().transAxes)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1,1.05))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
