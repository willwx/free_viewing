{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190cce5-9e51-4577-856d-31611e79acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../lib')\n",
    "from storage import get_storage_functions, quantize\n",
    "from local_paths import preproc_dir, analysis_dir\n",
    "from self_consistency import \\\n",
    "    find_return_fixations, pairwise_self_consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0248c-ad1d-43d2-8620-18005f04756b",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d49c84-3790-4c27-95f8-1c6c13585d9b",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# session\n",
    "#============================================================================\n",
    "sess_name = 'sess_name'\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# response windows\n",
    "#============================================================================\n",
    "t_pre  = 200\n",
    "t_post = 375\n",
    "t_step =  10\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# return fixation selection\n",
    "#============================================================================\n",
    "return_thres = 1  # for defining \"return fixation\"; can set to typical radius of rf\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# other miscellaneous\n",
    "#============================================================================\n",
    "n_boots = 200\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# paths\n",
    "#============================================================================\n",
    "proc_dir = preproc_dir\n",
    "sdf_dir = preproc_dir\n",
    "sdf_suffix = '-mwa_50'\n",
    "\n",
    "output_dir = analysis_dir + 'fix0_self_consistency'\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# misc\n",
    "#============================================================================\n",
    "n_jobs = 1  # for numba; <= 1: fractional; > 1: integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e824d1-6964-404f-83aa-3d87ed2ea3fd",
   "metadata": {},
   "source": [
    "# Check prerequisite and whether already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779bf63-3446-4291-85b2-68018aeadda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_path = Path(proc_dir) / (sess_name + '-proc.h5')\n",
    "print('Loading shared processing from', proc_path)\n",
    "proc_path = proc_path.expanduser()\n",
    "assert proc_path.is_file()\n",
    "\n",
    "preproc_main_path = Path(preproc_dir) / (sess_name + '-main.nwb')\n",
    "preproc_events_path = Path(preproc_dir) / (sess_name + '-events.h5')\n",
    "print('Loading preprocessed data from:')\n",
    "print('\\tmain:\\t', preproc_main_path)\n",
    "print('\\tevents:\\t', preproc_events_path)\n",
    "preproc_main_path = preproc_main_path.expanduser()\n",
    "preproc_events_path = preproc_events_path.expanduser()\n",
    "assert preproc_main_path.is_file()\n",
    "assert preproc_events_path.is_file()\n",
    "\n",
    "sdf_path = Path(sdf_dir) / (sess_name + f'-sdf{sdf_suffix}.h5')\n",
    "print('Loading spike density function from', sdf_path)\n",
    "sdf_path = sdf_path.expanduser()\n",
    "assert sdf_path.is_file()\n",
    "\n",
    "output_dir = Path(output_dir)\n",
    "assert output_dir.expanduser().is_dir()\n",
    "output_path = output_dir / (sess_name + '.h5')\n",
    "print('Saving results to', output_path)\n",
    "output_path = output_path.expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a7467e-4292-4f49-b0e3-22ef941a40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'fix0_self_consistency'\n",
    "\n",
    "if output_path.is_file():\n",
    "    with h5.File(output_path, 'r') as f:\n",
    "        try:\n",
    "            if f[f'progress_report/{analysis_name}/all_done'][()].item():\n",
    "                raise RuntimeError(f'{sess_name} has already been processed')\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c3e806-4e71-4faf-aa81-b0684d245635",
   "metadata": {},
   "source": [
    "# Prepare parameters; save config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113cda5-2d5d-4b06-8ecf-7b19e2723afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(proc_path, 'r') as f:\n",
    "    random_seed = f['config/default_random_seed'][()]\n",
    "    fix_sel = f['fixation_selection/fixation_indices'][()]\n",
    "fix_df = pd.read_hdf(proc_path, 'fixation_dataframe', 'r')\n",
    "\n",
    "print('random_seed:', random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b15e1-cf9b-47f2-b16a-e042413994ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0 == fix_df.index.get_level_values(fix_df.index.names.index('Fixation'))[fix_sel]\n",
    "print(f'from {m.size} fixations, selecting {m.sum()} ({m.mean()*100:.1f}%) zeroth-fixations')\n",
    "fix_sel = fix_sel[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fefe126-a643-49d0-9595-b3b640ffb64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results, add_attr_to_dset, check_equals_saved, link_dsets, copy_group = \\\n",
    "    get_storage_functions(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1030c-ec90-4217-9d5a-c157e1ad7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = analysis_name + '/config/'\n",
    "save_results(group+'random_seed', random_seed)\n",
    "save_results(group+'sdf_suffix', sdf_suffix)\n",
    "\n",
    "group = analysis_name + '/config/time_windows/'\n",
    "save_results(group+'t_pre', t_pre)\n",
    "save_results(group+'t_post', t_post)\n",
    "save_results(group+'t_step', t_step)\n",
    "add_attr_to_dset(group, attrs=dict(unit='ms'))\n",
    "\n",
    "group = analysis_name + '/config/return_criterion/'\n",
    "save_results(group+'return_thres', return_thres, attrs=dict(unit='dva'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaa0074-1083-4784-a6ff-6e223b1ae607",
   "metadata": {},
   "source": [
    "# Exclude trials showing fixation point unless all did\n",
    "\n",
    "Rationale: If only a subset of trials showed fixation, it may be spuriously correlated with image identity, leading to self-consistency in the fixation-point responses, thus resulting in incorrect (early) latency. If all trials showed the fixation point, there would be no spurious correlation. (Self-consistency depends on differential responses to images.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eae87a4-6e36-479d-b809-c2b2f38ce132",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(preproc_main_path, 'r') as f:\n",
    "    trial_ids = f['intervals/trials/id'][()]\n",
    "    trial_t0s = f['intervals/trials/start_time'][()]\n",
    "    trial_t1s = f['intervals/trials/stop_time'][()]\n",
    "\n",
    "with h5.File(preproc_events_path, 'r') as f:\n",
    "    event_ts = f['events/times'][()]\n",
    "    event_vs = f['events/words'][()]\n",
    "\n",
    "trial_df = pd.DataFrame({\n",
    "    'Trial': trial_ids,\n",
    "    'Start time': trial_t0s * 1e3,\n",
    "    'End time': trial_t1s * 1e3,\n",
    "}).set_index('Trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98e639-8297-49c6-b5dd-b2a8106a6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_itrs = fix_df.index.get_level_values(fix_df.index.names.index('Trial'))\n",
    "uitrs = fix_itrs.unique().values\n",
    "uitrs_excl_mask = np.zeros_like(uitrs, dtype=bool)\n",
    "\n",
    "# the follow code is specific to which & when digital event words were sent by the task implementation\n",
    "fix_on_code = 5\n",
    "fix_off_code = 6\n",
    "t_tol = 5\n",
    "\n",
    "i0 = 0\n",
    "for iitr, itr in enumerate(tqdm(uitrs)):\n",
    "    # add some slack to mae sure word is not missed\n",
    "    tt0, tt1 = trial_df.loc[itr, ['Start time', 'End time']] + [-50, 50]\n",
    "    st0 = fix_df.loc[(itr, slice(None)),]['Time'].max() + 50\n",
    "\n",
    "    # find relevant word indices\n",
    "    it0 = np.searchsorted(event_ts[i0:], tt0) + i0\n",
    "    is0 = np.searchsorted(event_ts[it0:], st0) + it0\n",
    "    it1 = np.searchsorted(event_ts[is0:], tt1) + is0\n",
    "\n",
    "    # clip off trial header if any\n",
    "    for i, w in enumerate(event_vs[it0:it1]):\n",
    "        if w == 3 and \\\n",
    "                np.array_equal(event_vs[it0+i:it0+i+5], [3, 2, 1, 255, 255]):\n",
    "            it0 = it0 + i + 5\n",
    "\n",
    "    # exclude any trial containing fix on or off event(s)\n",
    "    for name, code in (('fix_on', fix_on_code), ('fix_off', fix_off_code)):\n",
    "        match = event_vs[it0:it1] == fix_on_code\n",
    "        count = match.sum()\n",
    "        # validate integrity; exclude any suspicious trials\n",
    "        if count > 1:\n",
    "            # sometimes one event can be multiply stamped\n",
    "            # check for this by the spread in timing\n",
    "            spread = event_ts[it0:it1][match].ptp()\n",
    "            if spread <= t_tol:\n",
    "                print(\n",
    "                    f'Cannot infer {name} time for trial {itr}! Found '\n",
    "                    'more than one corresponding event '\n",
    "                    f'(count = {count}, spread = {spread:.3f} ms)')\n",
    "                uitrs_excl_mask[iitr] = True\n",
    "\n",
    "        if count > 0:\n",
    "            uitrs_excl_mask[iitr] = True\n",
    "\n",
    "    i0 = it1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4607e1db-9014-44e5-b73d-a922253fa3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = uitrs_excl_mask\n",
    "if m.all():\n",
    "    print(f'all trials ({m.sum()}) showeed a fixation point')\n",
    "else:\n",
    "    print(f'excluding {m.sum()} trials ({m.mean()*100:.1f}%) that may have shown a fixation point before image onset')\n",
    "    fix_excl_idc = np.nonzero(fix_itrs.isin(uitrs[uitrs_excl_mask]))[0]\n",
    "    m = ~pd.Series(fix_sel).isin(fix_excl_idc)\n",
    "    print(f'from {m.size} zeroth fixations, selecting {m.sum()} ({m.mean()*100:.1f}%) that did not involve a fixation point in the trial')\n",
    "    fix_sel = fix_sel[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41344758-b5dc-4dad-ad4a-adacbee62f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(analysis_name+'/fixation_selection', fix_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9732ce-68ac-4cef-be25-b0c0b5d49f88",
   "metadata": {},
   "source": [
    "# Find return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754f273-e25e-43b8-b02d-86abe185d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = fix_df.iloc[fix_sel]\n",
    "imids = np.array([f'{v0}/{v1}' for v0, v1 in df_[['Image subdir', 'Image filename']].values])\n",
    "posns = df_[['Relative X', 'Relative Y']].values\n",
    "\n",
    "return_pairs = find_return_fixations(imids, posns, thres_deg=return_thres)\n",
    "same_im_pairs = find_return_fixations(imids, np.zeros_like(posns), thres_deg=return_thres)\n",
    "\n",
    "print('Return fixations pairs shape:', return_pairs.shape)\n",
    "print('Same image pairs shape:', same_im_pairs.shape)\n",
    "\n",
    "bycond_return_pairs = dict(\n",
    "    return_fixation=return_pairs,\n",
    "    same_image=same_im_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd5583-fe6a-4115-8533-c5abbd8c7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = analysis_name + '/return_pairs/'\n",
    "for cond, pairs in bycond_return_pairs.items():\n",
    "    if not pairs.size:\n",
    "        pairs = h5.Empty('i')\n",
    "    save_results(group+cond, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f0c60b-e032-46e2-9b8b-b0ef0fd36a1d",
   "metadata": {},
   "source": [
    "# Get stimulus onset-aligned responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436138cb-0844-4db3-bf35-3fe5dc55ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(sdf_path, 'r') as f:\n",
    "    dset = f['sdf']\n",
    "    unit_names = dset.attrs['unit_names'].astype(str)\n",
    "    sdf = dset[()]\n",
    "    if 'unit_names' in f:\n",
    "        copy_group(f, 'unit_names', analysis_name+'/unit_names')\n",
    "\n",
    "n_neur = sdf.shape[1]\n",
    "unit_names.shape, unit_names.dtype, sdf.shape, sdf.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56352f3a-2b45-4874-a342-a900d2614294",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.arange(-t_pre, t_post, t_step)\n",
    "\n",
    "resps = np.empty_like(sdf, shape=(fix_sel.size, ts.size, sdf.shape[-1]))\n",
    "for i, t in enumerate(fix_df.iloc[fix_sel]['Time'].values):\n",
    "    ts_ = np.round(t+ts).astype(int)\n",
    "    resps[i] = sdf[ts_,:]\n",
    "\n",
    "resps.shape, resps.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294dbe42-5b3c-4fb7-9fa6-0296c05750dd",
   "metadata": {},
   "source": [
    "# Calculate self-consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abf977-2db0-4a90-bfa5-8ee1d5d6e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = (('time', ts), ('unit', unit_names))\n",
    "attrs = dict(\n",
    "    return_thres=return_thres,\n",
    "    random_seed=random_seed,\n",
    "    unit=\"Pearson's r\"\n",
    ")\n",
    "\n",
    "bycond_rsc_ds = {}\n",
    "for cond, pairs in bycond_return_pairs.items():\n",
    "    if len(pairs) > 1:\n",
    "        attrs['n_pairs'] = len(pairs)\n",
    "        ds = pairwise_self_consistency(\n",
    "            pairs=pairs, resps=resps,\n",
    "            n_bootstraps=n_boots, n_permutations=0,\n",
    "            random_seed=random_seed,\n",
    "            coords=coords, attrs=attrs)\n",
    "    else:\n",
    "        ds = None\n",
    "    bycond_rsc_ds[cond] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a935c-c099-42e7-aa4b-f8c338d8206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = analysis_name + '/'\n",
    "q = lambda x: quantize(x, 3)\n",
    "compr = dict(zlib=True, complevel=9)\n",
    "for cond, dataset in bycond_rsc_ds.items():\n",
    "    loc = group + cond\n",
    "    if dataset is not None:\n",
    "        dataset = dataset.assign({\n",
    "            k: q(v)\n",
    "            for k, v in dataset.data_vars.items()})\n",
    "        encoding = {\n",
    "            k: dict(chunksizes=v.shape, **compr)\n",
    "            for k, v in dataset.data_vars.items()\n",
    "            if v.size}\n",
    "        dataset.to_netcdf(\n",
    "            output_path, group=loc, mode='a',\n",
    "            engine='h5netcdf', encoding=encoding)\n",
    "    else:\n",
    "        save_results(loc, h5.Empty('f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe95e7a-eca2-4592-88d8-d574c8dcb2af",
   "metadata": {},
   "source": [
    "# Wrap up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc50ae02-61b8-49e6-8618-2d352b394165",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(f'progress_report/{analysis_name}/all_done', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b8472-b319-46b8-823b-b50ae9549993",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark -vm --iversions -rbg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e450c6-6e0b-4ab4-90c9-f4c4a5472994",
   "metadata": {},
   "source": [
    "# Basic visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4edad97-3dfe-4d04-a342-cae13c230afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace4163-6e48-4c88-b3de-f7e67788ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts, resps.mean((0,2)))\n",
    "plt.xlabel('Time to stimulus onset, ms')\n",
    "plt.ylabel('Grand mean firing rate, spikes/s');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d1a9a-0bf7-472a-96d4-9b7e8946273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(v is not None for v in bycond_rsc_ds.values()):\n",
    "    for k, color in (\n",
    "            ('return_fixation', 'tab:purple'),\n",
    "            ('same_image', 'k'),\n",
    "    ):\n",
    "        value = bycond_rsc_ds[k]\n",
    "        if value is None: continue\n",
    "        val = value['sample'].values\n",
    "        m = np.nanmean(val, -1)\n",
    "        s = np.nanmedian(val, -1)\n",
    "        l, = plt.plot(ts, m, label=k.capitalize(), color=color)\n",
    "        plt.fill_between(ts, m-s, m+s, ec='none', fc=l.get_color(), alpha=0.2)\n",
    "    plt.xlabel('Time to fixation onset, ms')\n",
    "    plt.ylabel('Self-consistency, Pearson\\'s r')\n",
    "    plt.legend(title='Return fixation type', loc='upper left', bbox_to_anchor=(1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
