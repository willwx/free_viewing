{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ca70c-ae5e-4b3e-95ef-7716fa294437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../lib')\n",
    "from local_paths import preproc_dir\n",
    "from storage import get_storage_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39472a5-521c-4149-b3b2-283b5332635d",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb3b29-cca5-4194-a6e0-b3fb1b374a98",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# session\n",
    "#============================================================================\n",
    "sess_name = 'sess_name'\n",
    "\n",
    "#============================================================================\n",
    "# target\n",
    "#============================================================================\n",
    "unit_dset = ''  # dset contaiing unit names; use . to indicate attr\n",
    "dsets = []  # a list of dsets (as an hdf5 key)\n",
    "unit_axes = []  # an int axis per dset\n",
    "dsets_to_copy = None  # None or a list of dsets\n",
    "\n",
    "#============================================================================\n",
    "# grouping\n",
    "#============================================================================\n",
    "stat = 'mean'  # np function name\n",
    "hiers = ['Unit', 'Channel', 'Bank', 'Array']\n",
    "save_unique_only = True  # if False, save all groups even if non-unique\n",
    "\n",
    "#============================================================================\n",
    "# paths\n",
    "#============================================================================\n",
    "annot_path = '../db/bank_array_regions.csv'\n",
    "input_dir = preproc_dir\n",
    "input_suffix = ''\n",
    "output_dir = preproc_dir\n",
    "output_suffix = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afec73d-974e-4509-b13b-36298ff982d2",
   "metadata": {},
   "source": [
    "# Check prereqs and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c34dbcd-bc13-46e3-922a-2fcb03a6d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(input_dir) / (sess_name + input_suffix + '.h5')\n",
    "print('Loading input from', input_path)\n",
    "input_path = input_path.expanduser()\n",
    "assert input_path.is_file()\n",
    "\n",
    "print('Loading recording array annotations from', annot_path)\n",
    "annot_path = Path(annot_path).expanduser()\n",
    "assert annot_path.is_file()\n",
    "adf = pd.read_csv(annot_path).set_index('Session').loc[[sess_name]].set_index('Bank')\n",
    "\n",
    "output_dir = Path(output_dir)\n",
    "assert output_dir.expanduser().is_dir()\n",
    "output_path = output_dir / (sess_name + output_suffix + '.h5')\n",
    "print('Saving results to', output_path)\n",
    "output_path = output_path.expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5134ad-de8c-45a0-b10e-01591e2408da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_str2seq(v):\n",
    "    if isinstance(v, str):\n",
    "        v = ast.literal_eval(v)\n",
    "        assert isinstance(v, list) or isinstance(v, tuple)\n",
    "    return v\n",
    "\n",
    "dsets = maybe_str2seq(dsets)\n",
    "unit_axes = maybe_str2seq(unit_axes)\n",
    "if dsets_to_copy is None:\n",
    "    dsets_to_copy = []\n",
    "else:\n",
    "    dsets_to_copy = maybe_str2seq(dsets_to_copy)\n",
    "\n",
    "assert len(dsets) == len(unit_axes)\n",
    "assert all(isinstance(a, int) for a in unit_axes)\n",
    "assert set(hiers) <= {'Unit', 'Channel', 'Bank', 'Array'}\n",
    "hiers = sorted(hiers, key=['Unit', 'Channel', 'Bank', 'Array'].index)\n",
    "\n",
    "stat_fun = np.__dict__[stat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb1bf8-15d3-4ae9-b7cb-be2e38ec6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results, add_attr_to_dset, check_equals_saved, link_dsets, copy_group = \\\n",
    "    get_storage_functions(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a087583-2de2-4793-8abc-92c2edc7e07a",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e7f42-0a9c-45df-afd3-475a1da2d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(input_path, 'r') as fi, h5.File(output_path, 'a') as fo:\n",
    "    if '.' in unit_dset:\n",
    "        i = unit_dset.rfind('.')\n",
    "        unit_dset_in = unit_dset[:i]\n",
    "        unit_dset_attr = unit_dset[i+1:]\n",
    "        unit_names = fi[unit_dset_in].attrs[unit_dset_attr].astype(str)\n",
    "        unit_dset_out = 'unit_names'\n",
    "    else:\n",
    "        unit_names = fi[unit_dset][()].astype(str)\n",
    "        unit_dset_in = unit_dset_out = unit_dset\n",
    "        unit_dset_attr = None\n",
    "    n_unit = len(unit_names)\n",
    "    unit_df = pd.DataFrame(data={'Name': unit_names})\n",
    "    unit_df['Channel'] = [int(re.search('\\d+', v).group()) for v in unit_names]\n",
    "    unit_df['Bank'] = (unit_df['Channel']-1) // 32\n",
    "    unit_df['Array'] = adf.loc[unit_df['Bank'].values, 'Array ID'].values\n",
    "\n",
    "    unique_groups = OrderedDict()\n",
    "    name2ig = OrderedDict()\n",
    "    for hier in hiers:\n",
    "        if hier == 'Unit': continue\n",
    "        for name, idc in unit_df.groupby(hier).groups.items():\n",
    "            if len(idc) < 2: continue\n",
    "            k = tuple(sorted(idc))\n",
    "            try:\n",
    "                name2ig[(hier, name)] = unique_groups[k]\n",
    "            except KeyError:\n",
    "                name2ig[(hier, name)] = unique_groups[k] = len(unique_groups)\n",
    "    ig2name0 = OrderedDict()\n",
    "    for name, ig in name2ig.items():\n",
    "        if not ig in ig2name0:\n",
    "            ig2name0[ig] = name\n",
    "    unique_groups_name = np.array(['/'.join(map(str, v)) for v in ig2name0.values()])\n",
    "    all_groups_name = np.array(['/'.join(map(str, v)) for v in name2ig.keys()])\n",
    "\n",
    "    for d in dsets_to_copy:\n",
    "        if d not in fo:\n",
    "            fi.copy(fi[d], fo, d)\n",
    "        else:\n",
    "            check_equals_saved(fi[d][()], fo[d][()], d)\n",
    "\n",
    "    names_ = None\n",
    "    for d, a in zip(dsets, unit_axes):\n",
    "        vals = fi[d][()]\n",
    "        assert vals.shape[a] == n_unit\n",
    "        vals = np.swapaxes(vals, a, 0)\n",
    "\n",
    "        gvals = np.empty_like(vals, shape=(len(unique_groups),*vals.shape[1:]))\n",
    "        for idc, i in unique_groups.items():\n",
    "            gvals[i] = stat_fun(vals[list(idc)], axis=0)\n",
    "\n",
    "        names = []\n",
    "        new_vals = []\n",
    "        if 'Unit' in hiers:\n",
    "            names.append([f'Unit/{v}' for v in unit_names])\n",
    "            new_vals.append(vals)\n",
    "        if name2ig:\n",
    "            if save_unique_only:\n",
    "                names.append(unique_groups_name)\n",
    "                new_vals.append(gvals)\n",
    "            else:\n",
    "                names.append(all_groups_name)\n",
    "                new_vals.append(gvals[list(name2ig.values())])\n",
    "\n",
    "        names = np.concatenate(names)\n",
    "        if names_ is None:\n",
    "            names_ = names\n",
    "        else:\n",
    "            assert np.array_equal(names_, names)\n",
    "        new_vals = np.concatenate(new_vals, axis=0)\n",
    "        new_vals = np.swapaxes(new_vals, 0, a)\n",
    "        if d in fo and 'hier_grouped' in fo[d].attrs:\n",
    "            check_equals_saved(new_vals, fo[d][()], d)\n",
    "        else:\n",
    "            attrs = {k: v for k, v in fi[d].attrs.items()}\n",
    "            attrs['hier_grouped'] = True\n",
    "            if d == unit_dset_in:\n",
    "                attrs[unit_dset_attr] = names.astype(bytes)\n",
    "            save_results(d, new_vals, overwrite=True)\n",
    "            for k, v in attrs.items():\n",
    "                fo[d].attrs[k] = v\n",
    "\n",
    "save_results(unit_dset_out, names.astype(bytes), overwrite=True)\n",
    "add_attr_to_dset(unit_dset_out, {\n",
    "    'all_groups_name': all_groups_name.astype(bytes),\n",
    "    'all_groups_uid': np.array(list(name2ig.values()))})\n",
    "save_results('hier_group/orig_unit_names', unit_names.astype(bytes))\n",
    "save_results('hier_group/hiers', np.array(hiers).astype(bytes))\n",
    "save_results('hier_group/stat', stat)\n",
    "save_results('hier_group/save_unique_only', save_unique_only)\n",
    "save_results('hier_group/groups/name', np.array(list(name2ig.keys())).astype(bytes))\n",
    "save_results('hier_group/groups/uid', np.array(list(name2ig.values())))\n",
    "for i, k in enumerate(unique_groups):\n",
    "    save_results(f'hier_group/groups/unit_indices/{i}', np.array(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec3f876-f52b-419d-8296-54fa6778a6b0",
   "metadata": {},
   "source": [
    "# Wrap up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf0c175-1086-4039-a2d6-adc4c90b16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results('progress_report/hier_group/all_done', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da6d7c-a96f-496d-844e-160febcf4b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -vm --iversions -rbg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
