{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3b49b-69c8-4eda-81e2-1682530f1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from hashlib import sha512\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../lib')\n",
    "from storage import get_storage_functions\n",
    "from local_paths import preproc_dir, eye_latency_calib_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe57f59c-1904-4bcc-82eb-d4750f2bacba",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# session\n",
    "#============================================================================\n",
    "sess_name = 'sess_name'\n",
    "\n",
    "#============================================================================\n",
    "# main\n",
    "#============================================================================\n",
    "fr_change_frac_thres = .5\n",
    "\n",
    "#============================================================================\n",
    "# paths\n",
    "#============================================================================\n",
    "proc_dir = preproc_dir\n",
    "output_dir = preproc_dir\n",
    "overwrite = False  # overwrite any existing results; use with caution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f2f38-6923-4868-ae55-8bc03725610c",
   "metadata": {},
   "source": [
    "# Check parameters and whether already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b4ab5-77d5-43b1-9e85-e44dae16e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_main_path = Path(proc_dir) / (sess_name + '-main.nwb')\n",
    "rasters_path = Path(proc_dir) / (sess_name + '-rasters.nwb')\n",
    "print('Loading session from', preproc_main_path)\n",
    "print('Loading rasters from', rasters_path)\n",
    "preproc_main_path = preproc_main_path.expanduser()\n",
    "rasters_path = rasters_path.expanduser()\n",
    "assert preproc_main_path.is_file()\n",
    "assert rasters_path.is_file()\n",
    "\n",
    "print('Using eye tracker latency calibration in:\\n\\t'+'\\n\\t'.join(map(str,eye_latency_calib_paths)))\n",
    "eye_latency_calib_paths = tuple(Path(v).expanduser() for v in eye_latency_calib_paths)\n",
    "assert all(v.is_file() for v in eye_latency_calib_paths)\n",
    "\n",
    "output_dir = Path(output_dir)\n",
    "assert output_dir.expanduser().is_dir()\n",
    "output_path = output_dir / (sess_name + '-proc.h5')\n",
    "print('Saving results to', output_path)\n",
    "output_path = output_path.expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb64951-a33c-41d8-b242-d5c75bd58a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not overwrite and output_path.is_file():\n",
    "    with h5.File(output_path, 'r') as f:\n",
    "        try:\n",
    "            if f['progress_report/shared_processing/all_done'][()].item():\n",
    "                raise RuntimeError(f'{sess_name} has already been processed')\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779bf63-3446-4291-85b2-68018aeadda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results, add_attr_to_dset, check_equals_saved, link_dsets, copy_group = \\\n",
    "    get_storage_functions(output_path, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02444a3c-a584-426f-bc34-6d2ecb4fe0ad",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf79bb6-1e67-458d-9f41-d6a722a6d594",
   "metadata": {},
   "source": [
    "### Save a default random seed (per-session, deterministic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d34eb-5444-4de2-a2cb-82d46b30d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = int(sha512(bytes(sess_name, 'utf-8')).hexdigest()[-8:], 16)\n",
    "print('random_seed:', random_seed)\n",
    "save_results('config/default_random_seed', random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c7460-b4d1-47db-be07-c98fd64dc3c1",
   "metadata": {},
   "source": [
    "### Save image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a4d47-0b13-49a7-bf15-42ae676252ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(preproc_main_path, 'r') as f:\n",
    "    im_size_px = f['stimulus/templates/stimuli/dimension'][()]\n",
    "    stim_desc = f['general/stimulus'][()].decode()\n",
    "\n",
    "print('stimuli:', stim_desc)\n",
    "ppd = stim_desc.split('pix per degree')[0].split('[')[-1].strip('] ').split(',')\n",
    "ppd = np.array(list(map(float, ppd)))\n",
    "im_size_dva = np.round(im_size_px / ppd, 1)\n",
    "\n",
    "print('image size (pixels):', im_size_px)\n",
    "print('image size (dva):', im_size_dva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a87fd8-df56-49bc-9228-f0371b0dc565",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results('stimulus/size_px', im_size_px)\n",
    "save_results('stimulus/size_dva', im_size_dva)\n",
    "save_results('stimulus/pixels_per_degree', ppd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d3184-b407-4aa0-ab26-f572474a9fa3",
   "metadata": {},
   "source": [
    "### Save stimulus folder(s): root and any subdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044022c-1ef6-4b42-8f91-abbe3e292363",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(preproc_main_path, 'r') as f:\n",
    "    uim_paths = f['stimulus/templates/stimuli/external_file'][()].astype(str)\n",
    "\n",
    "# find longest shared root dir\n",
    "if any('\\\\' in v for v in uim_paths):  # Windows paths\n",
    "    uim_subds = np.char.split(uim_paths, '\\\\')\n",
    "else:\n",
    "    uim_subds = np.char.split(uim_paths, '/')\n",
    "for i in range(min(map(len, uim_subds))):\n",
    "    if len(set(v[i] for v in uim_subds)) > 1:\n",
    "        i -= 1\n",
    "        break\n",
    "\n",
    "im_root = '/'.join(uim_subds[0][:i+1])\n",
    "uim_fns = np.array([v[-1] for v in uim_subds])\n",
    "uim_subds = np.array(['/'.join(v[i+1:-1]) for v in uim_subds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd348959-fc83-4732-8d09-472fd3fc2925",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results('stimulus/folder', im_root)\n",
    "save_results('stimulus/subdirectories', np.array(sorted(set(uim_subds))).astype(bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ea256-ab4e-48f4-9f4a-0c886fe7c5c6",
   "metadata": {},
   "source": [
    "### Get (rig-specific, measured) eye latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68280e0e-9305-4128-b4c7-57a87110e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker, rig = pd.read_csv(eye_latency_calib_paths[0], converters={'Eye tracker': str})\\\n",
    "    .set_index('Name').loc[sess_name][['Eye tracker', 'Rig']]\n",
    "tracker = tracker.split(' ')[-1]\n",
    "tracker_latency = pd.read_csv(eye_latency_calib_paths[1], converters={'Tracker': str})\\\n",
    "    .set_index(['Rig', 'Tracker']).loc[(rig, tracker)]['Latency']\n",
    "tracker_latency_rule = f'rig {rig}, tracker: {tracker}'\n",
    "print(f'Correcting eye tracking timing by {tracker_latency} ms ({tracker_latency_rule})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5270121-9a55-495d-92a0-91d28b23ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results('config/eye_tracking_latency', tracker_latency, attrs=dict(unit='ms'))\n",
    "save_results('config/eye_tracking_latency_rule', tracker_latency_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d5b1a-dc83-4668-935d-90b945b6f1d5",
   "metadata": {},
   "source": [
    "### Save formatted fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f06faa-6715-402d-87fc-2b4b6e75ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_df = {'Time': 'start_time', 'End time': 'stop_time', 'Trial': 'trial_id', 'Screen X': 'x', 'Screen Y': 'y'}\n",
    "with h5.File(preproc_main_path, 'r') as f:\n",
    "    try:\n",
    "        group = f['processing/behavior/fixations']\n",
    "    except KeyError:  # compat\n",
    "        group = f['processing/fixation_detection/fixations']\n",
    "    for k, v in fix_df.items():\n",
    "        fix_df[k] = group[v][()]\n",
    "        if k == 'Trial':\n",
    "            fix_df[k] = fix_df[k].astype(int)  # pytables does not like uint64 as an index\n",
    "\n",
    "fix_df = pd.DataFrame(fix_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befef2b6-a8d7-4471-b3b1-e34b461c31d2",
   "metadata": {},
   "source": [
    "Compensate for tracker latency before further formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deed8f0-e0d6-483d-a8ca-29b8be8bd784",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_df['Time'] -= tracker_latency/1e3\n",
    "fix_df['End time'] -= tracker_latency/1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fde5c68-a485-4c81-b9db-286a6ae8c9f1",
   "metadata": {},
   "source": [
    "Cross-reference fixations to stimulus presentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550d9d4-8499-496e-9028-13b82fc6812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(preproc_main_path, 'r') as f:\n",
    "    pres_iim = f['stimulus/presentation/presentations/data'][()]\n",
    "    pres_tid = f['intervals/presentations/trial_id'][()]\n",
    "    pres_t0s = f['intervals/presentations/start_time'][()]\n",
    "    pres_t1s = f['intervals/presentations/stop_time'][()]\n",
    "    pres_pos = f['intervals/presentations/position'][()]\n",
    "\n",
    "im_fns = uim_fns[pres_iim]\n",
    "im_subdirs = uim_subds[pres_iim]\n",
    "pres_df = pd.DataFrame({\n",
    "    'Trial': pres_tid,\n",
    "    'Start time': pres_t0s,\n",
    "    'End time': pres_t1s,\n",
    "    'X': pres_pos[:,0],\n",
    "    'Y': pres_pos[:,1],\n",
    "    'Image filename': im_fns,\n",
    "    'Image subdir': im_subdirs,\n",
    "}).set_index('Trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0649d1-e7fa-4e35-a37b-8319ea5ab5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not all fixations were during image presentation; select those that overlap in part with pres time\n",
    "fix_df = fix_df[fix_df['Trial'].isin(pres_tid)]\n",
    "pres_df_ = pres_df.loc[fix_df['Trial']]\n",
    "in_pres = (\n",
    "    ((fix_df['End time'].values - pres_df_['Start time'].values) > 0)\n",
    "    & ((fix_df['Time'].values - pres_df_['End time'].values) <= 0)\n",
    ")\n",
    "fix_df = fix_df[in_pres]\n",
    "pres_df_ = pres_df.loc[fix_df['Trial']]\n",
    "\n",
    "# find and clip fixations across stim onset to onset time\n",
    "is_zeroth = fix_df['Time'].values <= pres_df_['Start time'].values\n",
    "fix_df.loc[is_zeroth, 'Time'] = pres_df_.loc[is_zeroth, 'Start time'].values\n",
    "\n",
    "# cast presentation-specific info to fixations\n",
    "fix_df[['Relative X', 'Relative Y']] = fix_df[['Screen X', 'Screen Y']] - pres_df_[['X', 'Y']].values\n",
    "fix_df[['Image filename', 'Image subdir']] = pres_df_[['Image filename', 'Image subdir']].values\n",
    "\n",
    "# add order of fixation in each trial\n",
    "fix_df['Fixation'] = pd.concat([\n",
    "    pd.Series(data=np.argsort(g['Time'])+1, index=g.index)\n",
    "    for _, g in fix_df.groupby('Trial')\n",
    "])\n",
    "# order starts with 0 only for trials containing a \"zeroth fixation\"; 1 otherwise\n",
    "m = fix_df['Trial'].isin(fix_df[is_zeroth]['Trial'])\n",
    "fix_df.loc[m, 'Fixation'] -= 1\n",
    "\n",
    "# add duration, time-since-stim-on; convert time s -> ms\n",
    "fix_df['Duration'] = fix_df['End time'] - fix_df['Time']\n",
    "fix_df['Trial time'] = fix_df['Time'] - pres_df_['Start time'].values\n",
    "assert (fix_df['Trial time'][fix_df['Fixation'] == 0] == 0).all()  # sanity checks\n",
    "assert (fix_df['Trial time'][fix_df['Fixation'] != 0] > 0).all()\n",
    "fix_df['Trial time'] = np.clip(fix_df['Trial time'], 0, None)\n",
    "fix_df[['Time', 'Trial time', 'End time', 'Duration']] *= 1e3\n",
    "\n",
    "# drop irrelevant columns; set index\n",
    "fix_df = fix_df.drop(columns=['Screen X', 'Screen Y'])\n",
    "fix_df = fix_df.set_index(['Trial', 'Fixation'])\n",
    "\n",
    "# add ref to prev fixation\n",
    "ipre = np.full(len(fix_df), -1, dtype=int)\n",
    "for i, (itr, ifix) in enumerate(fix_df.index):\n",
    "    try:\n",
    "        ipre[i] = fix_df.index.get_loc((itr, ifix-1))\n",
    "    except KeyError:\n",
    "        pass\n",
    "fix_df['Preceding fixation index'] = ipre\n",
    "\n",
    "print(fix_df.shape)\n",
    "fix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827f8ff9-77ae-4a46-8857-5b603594c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_df.to_hdf(output_path, 'fixation_dataframe', mode='a', format='table', complevel=9, complib='zlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996be98-1c8d-4e95-9a80-9a0d17ac4dd9",
   "metadata": {},
   "source": [
    "### Select neurons\n",
    "\n",
    "Using minimal criteria to only exclude clearly technical problems:\n",
    "1. FR in 2nd half of data must not be 0 (if so, it is most likely the unit was lost)\n",
    "2. FR in 2nd half of data must not be > 150% or < 50% of overall FR (if so, it is most likely the unit was not stable)\n",
    "\n",
    "Criteria more meaningful for downstream analysis (e.g., visual responsiveness) can be applied downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01375fa0-8711-45d8-9010-d09289cc5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(rasters_path, 'r') as f:\n",
    "    unit_names = f['processing/ecephys/unit_names/unit_name'][()].astype(str)\n",
    "    rasters = f['processing/ecephys/rasters/data'][()]\n",
    "duration = len(rasters)\n",
    "all_unit_names = unit_names.copy()\n",
    "\n",
    "l = rasters.shape[0]\n",
    "fr = rasters.mean(0)*1e3\n",
    "fr1 = rasters[l//2:].mean(0)*1e3\n",
    "\n",
    "dfr = fr1 / fr - 1\n",
    "\n",
    "m0 = fr1 == 0\n",
    "m1 = np.abs(dfr) > fr_change_frac_thres\n",
    "m = m1|m0\n",
    "\n",
    "print('total', m.size, 'units:')\n",
    "print(f'excluding {m0.sum()} ({m0.mean()*100:.1f}%) unit(s) without spikes in second half of recording')\n",
    "print(f'excluding {m1.sum()} ({m1.mean()*100:.1f}%) unstable unit(s)')\n",
    "print(f'excluding {m.sum()} ({m.mean()*100:.1f}%) total unit(s)')\n",
    "unit_names = unit_names[~m]\n",
    "print('keeping', (~m).sum(), 'units:')\n",
    "print('\\t' + '\\n\\t'.join(str(unit_names).split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f3388-a402-427d-8d02-83ddbcf7419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results('recording_duration', duration, attrs=dict(unit='ms'))\n",
    "save_results('config/unit_selection/fr_change_frac_thres', fr_change_frac_thres)\n",
    "save_results('unit_selection/all', all_unit_names.astype(bytes))\n",
    "save_results('unit_selection/simple', unit_names.astype(bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1b8f29-c8b2-44c1-b621-c03df29304fc",
   "metadata": {},
   "source": [
    "### Calculate response stats\n",
    "I.e., response mean and stdev, during stimulus and inter-stimulus periods respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c150b9-bba0-4bc9-8a85-1a8a67944db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_stim = np.zeros(len(rasters), dtype=bool)\n",
    "for t0, t1 in np.round(np.array([pres_t0s, pres_t1s]).T).astype(int):\n",
    "    is_stim[t0:t1] = True\n",
    "byper_mean_std = np.empty((2, 2, rasters.shape[1]))\n",
    "for iper in range(2):\n",
    "    m = is_stim if iper else ~is_stim\n",
    "    vals = rasters[m]\n",
    "    byper_mean_std[iper, 0] = vals.mean(0) * 1e3\n",
    "    byper_mean_std[iper, 1] = vals.std(0) * 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10471a0f-4c0d-4729-b65e-279b8ab4fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(\n",
    "    'response_stats/stim_spont_mean_std',\n",
    "    byper_mean_std,\n",
    "    attrs=dict(\n",
    "        dims=np.array(['period', 'statistic', 'unit'], dtype=bytes),\n",
    "        period=np.array(['inter-stimulus', 'stimulus'], dtype=bytes),\n",
    "        statistic=np.array(['mean', 'stdev'], dtype=bytes),\n",
    "        unit=all_unit_names.astype(bytes),\n",
    "        num_ms=np.array([(~is_stim).sum(), is_stim.sum()]),\n",
    "        unit_='spikes/s',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca012873-d3b3-4c3c-a9c7-87813a28fed7",
   "metadata": {},
   "source": [
    "# Wrap up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf40eea-339a-45be-9dd9-13ac8741ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results('progress_report/shared_processing/all_done', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc6a9e-8226-438e-9337-d46eae7ce37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -vm --iversions -rbg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30084ed1-8247-49cb-ad27-3a4fcc88509e",
   "metadata": {},
   "source": [
    "# Quick plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ff434-a5bc-4878-be65-b5034d945c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f14aa5-6517-4060-a512-0aa007fd3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8,3))\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    vals = byper_mean_std[:,i]\n",
    "\n",
    "    ax.scatter(*vals, s=10)\n",
    "    u, l = vals.min(), vals.max()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.plot([u,l], [u,l], lw=1, ls='--', zorder=-1, color='gray')\n",
    "    if i == 0:\n",
    "        ax.set_title('Mean')\n",
    "    else:\n",
    "        ax.set_title('Stdev.')\n",
    "    ax.set_xlabel('Inter-stimulus period')\n",
    "    ax.set_ylabel('Stimulus period')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
