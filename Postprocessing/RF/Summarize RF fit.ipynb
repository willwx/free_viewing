{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce64a4-6b13-4c38-82ce-d2fa067961b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "\n",
    "sys.path.append('../../lib')\n",
    "from local_paths import analysis_dir\n",
    "from hier_group import unpack_hier_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d08f53-226e-44d4-8fae-1b4fc6fd4395",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60677ccd-412b-4a2c-8a5d-8b8ff3d01ca3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# analysis type and result path\n",
    "#============================================================================\n",
    "rf_fit_group = 'rf_fit/opt/per_split'  # formatted as in the rf_gaussian_fit script\n",
    "# rf_fit_group = 'rf_fit/opt/across_splits'\n",
    "results_subdir = 'feat_corr_map-hg-fix-rf_fit'\n",
    "\n",
    "#============================================================================\n",
    "# selection criteria\n",
    "#============================================================================\n",
    "rf_fit_thres = {'rf_at_fit_peak': 0.04, 'goodness_of_fit': 0.7, 'fit_coverage': 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92868211-0fb5-4167-ab5b-26d49900f12b",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07cb20-6322-4ce7-8af6-e7850f555bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path(analysis_dir+results_subdir).expanduser()\n",
    "assert results_dir.is_dir()\n",
    "\n",
    "cols_to_save = ['x', 'y', 'r', 'goodness_of_fit', 'rf_fit_weighted_mean', 'a', 'b', 'ang_rad']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a725b0f1-b77b-4723-9e3a-f69912e180d7",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ee17e-b77f-44d1-9c1d-65efeb0107fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "has_split = None\n",
    "for fp in results_dir.glob('*.h5'):\n",
    "    with h5.File(fp, 'r') as f:\n",
    "        try:\n",
    "            assert f['progress_report/rf_fit/all_done'][()]\n",
    "        except (KeyError, AssertionError):\n",
    "            continue\n",
    "\n",
    "    rf_fit_ds = xr.load_dataset(fp, group=rf_fit_group)\n",
    "    with h5.File(fp, 'r') as f:\n",
    "        rf_unit_names = f['rf_fit/unit_names'][()].astype(str)\n",
    "    rf_fit_data = rf_fit_ds['data'].loc[{'unit':rf_unit_names}]\n",
    "\n",
    "    if has_split is None:\n",
    "        has_split = 'split' in rf_fit_data.dims\n",
    "    else:\n",
    "        assert has_split == ('split' in rf_fit_data.dims)\n",
    "\n",
    "    # reshape data; ensure only one condition exists\n",
    "    dims_ = tuple(set(rf_fit_data.dims) - {'unit','feature','split'})\n",
    "    assert np.prod([rf_fit_data.coords[d].size for d in dims_]) == 1\n",
    "    if has_split:\n",
    "        new_dims = dims_ + ('split', 'unit', 'feature')\n",
    "    else:\n",
    "        new_dims = dims_ + ('unit', 'feature')\n",
    "    rf_fit_data = rf_fit_data.transpose(*new_dims)\n",
    "\n",
    "    # reformat as dataframe\n",
    "    data = rf_fit_data.values.reshape(-1, rf_fit_data.shape[-1])\n",
    "    rf_df = pd.DataFrame(data=data, columns=rf_fit_data.coords['feature'].astype(str))\n",
    "    index = unpack_hier_names(rf_unit_names)\n",
    "    if has_split:\n",
    "        rf_df['Split'] = rf_fit_data['split'].broadcast_like(rf_fit_data.isel(feature=0)).values.ravel()\n",
    "        rf_df[['Level', 'Name']] = np.concatenate([index]*rf_fit_data['split'].size, axis=0)\n",
    "    else:\n",
    "        rf_df[['Level', 'Name']] = index\n",
    "    rf_df['Session'] = fp.stem\n",
    "    df.append(rf_df)\n",
    "\n",
    "df = pd.concat(df)\n",
    "if has_split:\n",
    "    df = df.set_index(['Session', 'Level', 'Name', 'Split'])\n",
    "else:\n",
    "    df = df.set_index(['Session', 'Level', 'Name'])\n",
    "assert not df.index.has_duplicates\n",
    "df['r'] = np.sqrt(np.prod(df[['a', 'b']], axis=1))\n",
    "print(df.shape)\n",
    "\n",
    "output_sfx = ('-across_splits', '')[has_split]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96b35e-3835-4a21-853b-6a67e660e203",
   "metadata": {},
   "source": [
    "# Select from all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dda9db-b139-4e6a-beac-593e7c252598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_rf_fit(rf_df, rf_fit_thres=rf_fit_thres):\n",
    "    criteria = {}\n",
    "    criteria['Is valid'] = np.isfinite(rf_df[list('xyab')].values).all(1)\n",
    "    for k, v in rf_fit_thres.items():\n",
    "        criteria[k] = rf_df[k] >= v\n",
    "\n",
    "    print(f'Selecting from {len(rf_df)} entries')\n",
    "    for k, m in criteria.items():\n",
    "        print(f'criterion: {k:<20} passed: {m.mean()*100:.1f}% ({m.sum()} of {m.size})')\n",
    "    m = np.all(list(criteria.values()), axis=0)\n",
    "    print(f'criterion: {\"All\":<20} passed: {m.mean()*100:.1f}% ({m.sum()} of {m.size})')\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf4a5d-75fa-483e-8051-da1eb9a8eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = df.copy()\n",
    "rf_df['Selected'] = select_rf_fit(rf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5badf9-d8d8-4d46-b27a-bfe13698b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df.loc[rf_df['Selected'], cols_to_save].to_csv(\n",
    "    f'summary/rf_fit{output_sfx}.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9d54d-53c2-4adf-a69f-00ede6d8a2d0",
   "metadata": {},
   "source": [
    "# Summarize array-level results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb5635-b94a-4c8e-b5b7-abb8a48ad7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "arreg = pd.read_csv('../../db/bank_array_regions.csv').astype({'Array ID': str})\n",
    "arreg['Subject'] = [v[:2] for v in arreg['Session']]\n",
    "arreg = arreg.groupby(['Subject', 'Array ID']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32190b-ca34-430f-a3ba-b733828593e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = df.reset_index()\n",
    "rf_df = rf_df[rf_df['Level']=='Array'].copy()\n",
    "rf_df['Selected'] = select_rf_fit(rf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a7ec8-02a5-4f90-995d-7155d82d54f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = rf_df[rf_df['Selected']].copy()\n",
    "adf['Subject'] = [v[:2] for v in adf['Session']]\n",
    "adf[['Region', 'Hemisphere']] = arreg.loc[list(map(tuple, adf[['Subject', 'Name']].values))][['Region', 'Hemisphere']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c22943-3417-4e3e-a1f2-b1c62e82287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Array-level RF fit, per session')\n",
    "fig, axs = plt.subplots(1, 3, figsize=(9,2.5))\n",
    "for x, ax in zip('xyr', axs):\n",
    "    sns.histplot(\n",
    "        data=adf, x=x, hue='Hemisphere', hue_order=('L','R'),\n",
    "        stat='density', element='poly', common_norm=False, fill=False, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf767f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Array-level estimates, median across sessions')\n",
    "df_ = adf.groupby(['Subject','Name']).agg({\n",
    "    'Region': 'first', 'Hemisphere': 'first', 'Selected': 'mean',\n",
    "    **{k: 'median' for k in cols_to_save}})\n",
    "assert df_['Selected'].all()  # sanity check\n",
    "fig, axs = plt.subplots(1, 3, figsize=(9,2.5))\n",
    "for i, (x, ax) in enumerate(zip('xyr', axs)):\n",
    "    sns.histplot(data=df_, x=x, hue='Hemisphere', stat='density', element='poly', common_norm=False, fill=False, ax=ax)\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054969a-c24c-4268-ad12-dae44cd22565",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Array-level estimates, median across arrays')\n",
    "df_.groupby(['Region', 'Hemisphere']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb92c62-86b1-4a76-b653-f9e146d9fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save array-level resuilts median across sessions\n",
    "gb = adf.groupby(['Subject', 'Name'])\n",
    "df_ = gb[cols_to_save].median()\n",
    "df_['Count'] = gb['x'].count()\n",
    "df_[['Region', 'Hemisphere']] = gb[['Region', 'Hemisphere']].first()\n",
    "df_['Level'] = 'Array'\n",
    "df_ = df_.reset_index().set_index(['Subject', 'Level', 'Name'])\n",
    "df_.to_csv(f'summary/rf_fit{output_sfx}-array_level.csv.gz')\n",
    "df_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
